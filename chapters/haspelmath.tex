\documentclass[output=paper]{langsci/langscibook} 
\ChapterDOI{10.5281/zenodo.2583804}
\author{Martin Haspelmath\affiliation{MPI-SHH Jena \& Leipzig University}}
\title{Can cross-linguistic regularities be explained by constraints on change?}
\abstract{This paper addresses a recent trend in the study of language variation and universals, namely to attribute cross-linguistic patterns to diachrony, rather than to other causal factors. This is an interesting suggestion, and I try to make the basic concepts clearer, by distinguishing clearly between language-particular regularities, universal tendencies, and mere recurrent patterns, as well as three kinds of causal factors (preferences, constraints, restrictions). I make four claims: (i) Explanations may involve diachrony in different ways; (ii) for causal explanations of universal tendencies, one needs to invoke mutational constraints (change constraints); (iii) in addition to mutational constraints, we need functional-adaptive constraints as well, as is clear from cases of multi-convergence; and (iv) successful functional-adaptive explanations do not depend on understanding the precise pathways of change.
}
\begin{document}
\maketitle 

\title{{Can cross-linguistic} regularities be explained by constraints on change?}

 
 

\section{Language universals: Constraints on cross-linguistic distributions as explananda}\label{sec:haspelmath:1}

Since \citet{Greenberg1963}, it has been widely recognized that comparison of languages with world-wide scope can give us not only taxonomies (as in earlier typology, e.g. \citealt{Schlegel1808,Schleicher1850}: 5–10; \citealt{Sapir1921}), but intriguing limits on cross-linguistic distributions: Especially when one looks at several parameters simultaneously, not all logically possible types are attested, or some types are far more common and others far less common than would be expected by chance. We would like to know why – or in other words, we are looking for causal explanations.

Since at least \citet{Chomsky1981}, many generative grammarians\is{generative linguistics} have also been interested in cross-linguistic regularities, and have often interpreted them as following from \isi{innate} principles of \isi{Universal Grammar} (UG) and their parametric variation. Others have tended to prefer functional explanations of universals (e.g. \citealt{Comrie1989,Stassen1985,Dixon1994,Dik1997,Hawkins2014_VarEff}), but these authors have likewise appealed primarily to general principles of language and sometimes have even adopted the term “universal grammar” (\citealt{KeenanComrie1977,FoleyVanValin1984,Stassen1985}).

In contrast to these two dominant approaches of the 1970s–1990s, there is an alternative view, according to which the explanation for universals of language structure comes from diachrony. The first well-known author in this tradition is \citet{Greenberg1969}, who stated that “[s]ynchronic regularities are merely the consequence of [diachronic] forces” (1969: 186). A straightforward example of the explanatory role of diachrony is the generalization that in languages with \isi{preposition}s, the \isi{possessor} generally follows the possessed noun\isi{possessive construction}, while in languages with \isi{postposition}s, it generally precedes it (\citegen{Greenberg1963} Universal 2; \citealt{Dryer1992}). This can be explained on the basis of the diachronic regularity that new \isi{adposition}s generally arise from possessed nouns in processes of \isi{grammaticalization} (\citealt{Lehmann1982_Thoughts}: §3.4.1; \citealt{Bybee1988}: 353–354; \citealt{chapters/collins,chapters/dryer} [both in  this volume]). For example, \ili{English} \textit{because (of)} comes from \textit{by + cause (of)}. Since the order of the elements remains stable in \isi{grammaticalization}, we have an explanation for the fact that the possessed noun and the \isi{adposition} tend to occur in the same position in languages.

The view that the explanation of language universals comes (at least sometimes) from diachrony has apparently been gaining ground over the last decade and a half. The early papers by \citet{Greenberg1969, Greenberg1978_Diachr} and \citet{Bybee1988} represented minority views (though \citealt{Givón1979} and \citealt{Lehmann1982} discussed diachronic change extensively and contributed to giving it a prominent place in functional-typological linguistics). Prominent papers in this vein in more recent years are \citet{Aristar1991}, \citet{Anderson2005, Anderson2008, Anderson2016}, \citet{Cristofaro2012, Cristofaro2013, Cristofaro2014}, \citet{Creissels2008}, \citet{GildeaZúñiga2016}, and in phonology, \citet{Blevins2004} is a book-length study that adopts a similar approach (see also \citealt{Blevins2006}). The following are a few key quotations from some of these papers (and from some others):

\eanoraggedright
  \ea “The question for typology is perhaps not what kinds of system are possible, but what kinds of change are possible.” \citep[195]{Timberlake2003}
  \newpage 
  \ex “recurrent synchronic sound patterns are a direct reflection of their diachronic origins, and, more specifically, ... regular phonetically based \isi{sound change} is the common source of recurrent sound patterns” (\citealt{Blevins2006}: 119–120)
  \ex “statistical universals are not really synchronic in nature, but are rather the result of underlying diachronic mechanisms that cause languages to change in preferred or ‘natural’ ways” (\citealt{BickelEtAl2015}: 29)
  \ex “there are no (or at least very few) substantive universals of language, and the regularities arise from common paths of diachronic change having their basis in factors outside of the defining properties of the set of cognitively accessible grammars” \citep[11]{Anderson2016}
  \z
\z

This paper has two major goals: First, I would like to contribute to conceptual clarification, sorting out what kinds of claims have been made and what terms have been used for which kinds of phenomena (\sectref{sec:haspelmath:2}).

Second, I argue that there are two ways in which diachrony and universals may interact: Some cross-linguistic generalizations are due to change constraints, as envisaged by the authors in (1), but others are due to functional-adaptive\is{adaptation} constraints. More specifically, I want to make four points:

\begin{itemize}
\item The notion of “diachronic explanation” is too vague, because explanations may involve diachrony in rather different ways (\sectref{sec:haspelmath:3}).
\item Universal tendencies cannot be explained by common pathways of change, only by change constraints, or what I call \isi{mutation}al constraints (\sectref{sec:haspelmath:4}).
\item Multi-\isi{convergence} clearly shows that functional-adaptive\is{adaptation} constraints are needed in order to explain at least some cross-linguistic regularities (\sectref{sec:haspelmath:5}).
\item Functional-adaptive\is{adaptation} explanations do not depend on understanding the pathways of change, though knowing about the pathways illuminates the explanations (\sectref{sec:haspelmath:6}).
\end{itemize}

Before arguing for these four points, I will discuss some technical terms in the next section, because there is often confusion between terms for language-particular regularities (\sectref{sec:haspelmath:2.1}), cross-linguistic regularities (\sectref{sec:haspelmath:2.2}), and causal factors (\sectref{sec:haspelmath:2.3}).

\section{Regularities and causal factors: Concepts and technical terms}\label{sec:haspelmath:2}

General terms such as \textit{restriction, constraint, preference, tendency, bias,} and \textit{motivation} have been used in diverse and sometimes confusing ways by linguists. This section clarifies how these terms are used in the present paper, noting along the way what other meanings some of them have been given and what other terms have been used for (roughly) the same concepts. I distinguish between terms for regularities and terms for causal factors, and within the terms for regularities, I distinguish between language-particular and cross-linguistic regularities.

\subsection{Language-particular regularities}\label{sec:haspelmath:2.1}

Regularities within a particular language can concern language use or the conventional language system. Regularities of language use are increasingly studied by \isi{corpus} linguistics, and they are often thought to be at the root of system regularities, especially in what is often called a “usage-based”\is{usage-based approach} view \citep{Bybee2010}. However, regularities of use and system regularities are conceptually different, and linguists normally distinguish clearly between \textit{parole} (language use) and \textit{langue} (language system). In what follows, I \isi{focus} on the systems of linguistic conventions.

For regularities within language systems, linguists normally use the general terms \textit{rule} and \textit{construction} (or \textit{schema}). In addition, descriptive linguists use many other well-established class (or category) terms like \textit{clause}, \textit{noun phrase}, \textit{suffix}, \textit{\isi{dative} \isi{case}}, or terms for relations between constructions such as \textit{alternation} or \textit{derivation}. All of these relate to systems of particular languages.

The term \textit{constraint} is sometimes applied to language-particular regularities, e.g. in constraint-based formalisms such as \isi{HPSG}, and optimality theory\is{Optimality Theory} also uses constraints for language-particular regularities. However, I will use this term exclusively for causal factors, as explained in \sectref{sec:haspelmath:2.3} below.

Language-particular regularities can also be seen as “explanations”, at least in the weak sense that they answer why-questions about lower-level regularities (“Why is there a Dative\is{dative} \isi{case} on the object of this sentence? Because the verb’s valency requires a Dative\is{dative}.”). Statements of rules or constructions may thus be called “descriptive explanations” if one wishes. In this paper, however, I \isi{focus} on causal explanations that help us explain the conventional systems of languages themselves.

\subsection{Cross-linguistic regularities: Recurrent patterns and universal tendencies}\label{sec:haspelmath:2.2}


Cross-linguistic regularities are typically generalizations over language-par\-tic\-u\-lar regularities,\footnote{However, comparative \isi{corpus} linguistics studies comparable corpora of language use, so there is no necessary connection between cross-linguistic comparison and the study of systems (as opposed to use).} and I will distinguish two kinds of regularities here. On the one hand, similar phenomena may be found in different parts of the world, e.g. \isi{ejective} consonants, or high vowel \isi{epenthesis}, or \isi{optative} \isi{mood} forms, or \isi{functive} markers \citep{Creissels2014}. These are called \textsc{recurrent patterns}. On the other hand, some regularities are so strong that we call them \textsc{universals}, because they occur with much greater than chance frequency. I also often use the term \textsc{universal tendencies}, because there is no claim that there are no \isi{exception}s.\footnote{Another term for a cross-linguistic distribution is \citegen{Bickel2013} family bias\is{Family Bias Method}, which means ‘preponderance within a family’. Note that this use of \textit{bias} is quite different from the more common use as in \textit{\isi{cognitive} bias} (e.g. \citealt{TverskyKahneman1974}); a term like \textit{family tendency} would probably be more transparent.}
\largerpage[2]

Recurrent patterns are not accidental similarities, in the sense that there must be something in the human condition that makes it possible for very similar linguistic categories to appear independently in languages that have no historical connection. However, the discovery of a recurrent pattern does not imply a claim about further languages.

By contrast, the discovery of a universal implies a claim about all other languages: If a universal holds (i.e. is found with much greater than chance frequency in a reasonably representative sample), it is claimed that it also holds in any other representative sample. Thus, claims of universal tendencies can be tested by examining data from the world’s languages, while claims of recurrent patterns can only be strengthened by additional further observations, but neither confirmed nor disproven by additional data. 

Universal tendencies need to be distinguished, in particular, from family-spe\-cif\-ic or region-specific trends, so they need to be based on a world-wide sample. A well-known example is the finding that in all major world regions, languages with OV order tend to have \isi{postposition}s, and languages with VO order tend to have \isi{preposition}s (\citealt{Greenberg1963}: Universal 2; \citealt{Dryer1992}: 83), even though many languages are \isi{exception}s. Another universal tendency is the limitation of nominal \isi{suppletion} to the most frequent nouns \citep{Vafaeian2013}, even though many languages do not have nominal \isi{suppletion} at all. We may even identify universal tendencies within patterns that are quite rare, e.g. universals of \isi{infixation} \citep{Yu2007}, because universal tendencies can be implicational\is{implicational universal} (“If a language has \isi{infixation}, then...”).

Recurrent patterns, by contrast, are not associated with any kind of global claim, so they could be called \textit{frequent patterns}, or \textit{sporadic patterns}, depending on one’s subjective assessment of their frequency. They are no doubt important for a complete account of human language, but they will be left aside in what follows, as it is not clear what causal factors might illuminate them.

\subsection{Causal factors: Preferences, constraints, restrictions}\label{sec:haspelmath:2.3}


In addition to documenting language-particular systems and cross-linguistic distributions, we also want to know what might explain the distributions in causal terms. The explanatory devices are called \textit{causal factors,} or \textit{(system-external) motivations}, or \textit{constraints}. Especially the latter term is short and relatively clear, so I will use it as the default term for a causal factor. (Two other terms that are used commonly as well, especially outside core linguistics, are \textit{force} and \textit{pressure}. It seems that all these terms are basically synonymous.)

If a constraint is very strong, it can also be called \textit{restriction}, and if it is weaker, it can be called \textit{preference.}\footnote{Another term for system-external causal factors is \textit{bias}, which is used in particular by psychologists for \isi{cognitive} preferences. Typical biases seem to be quite weak, so that even detecting them is an important part of research. By contrast, linguists’ constraints are often very strong, and controversy concerns primarily the nature (functional-adap\-tive\is{adaptation}, representational, \isi{mutation}al) and the interaction of the constraints.} This seems to be in line with much current usage in linguistics. There is thus no objective difference between restrictions, constraints and preferences, and we could use one of the three terms for all types of constraints. (This situation is similar to the cases of sporadic and frequent patterns, which are subjective sub-cases of recurrent patterns.)

Depending on the way in which they affect cross-linguistic distributions, here I distinguish four types of constraints (or restrictions, or preferences), which can be briefly characterized as in \REF{ex:haspelmath:2}.

\eanoraggedright\label{ex:haspelmath:2} 
  \ea \textit{functional-adaptive\is{adaptation} constraints}: what facilitates communication (including \isi{processing}) for speakers and hearers
  \ex \textit{representational constraints}: what is \isi{innate}ly preferred or necessary in the \isi{cognitive} representation of language
  \ex \textit{\isi{mutation}al constraints}: what is preferred or necessary in language change (= change constraints)
  \ex \textit{acquisitional constraints}:  what is preferred or necessary in \isi{acquisition} by children
  \z
\z

\textsc{Functional-adaptive\is{adaptation} constraints} are the kinds of factors that have been invoked by functionalists to explain cross-linguistic distributions (e.g. \citealt{Tomlin1986,Malchukov2008,Hawkins2014_VarEff}; among many others). For example, phonological inventories favour five-vowel systems because these make the best use of the acoustic space (\citealt{DeBoer2001}), and \isi{case} systems favour overt \isi{ergative}s for low-prominence nominals and overt \isi{accusative}s for high-prominence nominals because of the association between roles and prominence status \citep{Dixon1994}. These constraints are called \textit{functional-adaptive\is{adaptation}} rather than merely \textit{functional} to emphasize their role in explaining systems, not usage (the functioning of language). Functional linguists often \isi{focus} on understanding the functioning of language in usage, but here my interest is in explaining how systems come to have properties that facilitate communication.\footnote{Another term for functional-adaptive\is{adaptation} constraint is “\isi{naturalness} parameter” \citep{DresslerEtAl1987}, and functional-adaptive\is{adaptation} changes have been called “natural changes”.} \citet{Good2008_Intro} uses the term “external explanation” in roughly this sense (cf. also \citealt{Newmeyer1998}: §3.4), but all four types of constraints are external in that they are not part of the system. (“System-internal explanation” is just another word for general regularities of language-particular systems, cf. \sectref{sec:haspelmath:2.1} above; I do not think that the notion of causality is relevant for such statements, so all causal explanatory factors are external.)

\textsc{Representational constraints} 
\label{p:haspelmath:representationalconstraints}
are the kinds of factors that have been invoked by generativists\is{generative linguistics} to explain grammatical universals, as noted in \sectref{sec:haspelmath:1}. In the \isi{Principles and Parameters} framework \citep{Chomsky1981}, they were called the principles of \isi{Universal Grammar}. For example, the principles of \isi{X-bar theory} or \isi{binding theory} have been regarded as representational constraints, as well as universal features and hierarchies of functional categories such as \isi{determiner} (e.g. \citealt{Cinque1999}). The general idea is that “the unattested patterns do not arise as they cannot be generated in a manner consistent with \isi{Universal Grammar}” \citep{SmithEtAl2018}. Representational constraints are usually regarded as very strong, i.e. as restrictions (and thus \isi{Universal Grammar} is said to be \textit{restrictive}; cf. also \citealt{Haspelmath2014_CompSyn}).\footnote{Cognitive\is{cognitive} linguists have also sometimes invoked representational constraints to explain universals, though these are not referred to as UG\is{Universal Grammar}. An example might be the idea in \citet{Croft1991} that all event types are modeled on the basic force-dynamic \isi{agent}-\isi{patient} event type. This is not very strong, i.e. it is a preference, but apparently a preference having to do with \isi{cognitive} representations, not with communicative or \isi{processing} preferences.} However, there is no intrinsic reason why representational constraints could not be weaker preferences, e.g. why there could not be a weak \isi{innate} preference to put elements into a “\isi{determiner}” category (though this possibility is almost never considered by linguists). In \citegen{Good2008_Intro} survey, representational constraints are treated under the label of “structural explanations”, but this term (like “system-internal explanations”) is better reserved for general statements of regularities of language-particular systems.

\textsc{Mutational\is{mutation} constraints} (or change constraints) are constraints on possible diachronic transitions or possible diachronic sources, which can have an effect on synchronic distributions. For example, if nasal vowels only ever arise from VN sequences, this explains that all languages with nasal vowels also have nasal consonants, and that nasal vowels are rarer than oral vowels in the lexicon \citep{Greenberg1978_Diachr}. Likewise, if infixes\is{infixation} only ever arise by \isi{metathesis} from adfixes (= prefixes or suffixes), this explains that they only occur in peripheral position \citep[51]{Plank2007}. And if \isi{adposition}s only arise from nouns in \isi{possessor}–noun constructions\is{possessive construction}, this explains that their position correlates\is{word-order correlation} with the position of possessed nouns\isi{possessive construction}, as noted in \sectref{sec:haspelmath:1}. The notion of \isi{mutation}al constraints is not new (\citealt{Plank2007}: §2 calls them “diachronic laws”), but I introduce a new term here in order to make clear that the causal factor is located within the process of change, rather than diachronic change merely realizing a pattern that is driven by functional-adaptive\is{adaptation} constraints (see \sectref{sec:haspelmath:3} below). One could also frame the contrast between \isi{mutation}al constraints and functional-adaptive\is{adaptation} constraints in terms of \textit{source-oriented} vs. \textit{result-oriented} factors \citep{Cristofaro2017},\footnote{Informally, instead of talking about “result-oriented factors”, one could also say that functional-adaptive\is{adaptation} constraints are “pull forces” that attract the variable development into a certain preferred state.} or one could say that \isi{mutation}al constraints locate the causal factors within the \textit{mechanisms} of change \citep{Bybee2006}. These are just alternative ways of saying that cross-linguistic distributions are due to \isi{mutation}al constraints.

\largerpage
Finally, \textsc{acquisitional constraints} are factors that impact the \isi{acquisition} of language and that have an effect on cross-linguistic distributions. Such constraints are briefly discussed by \citet{Anderson2016}, but they do not seem to play a big role in linguistics (but cf. \citealtv{chapters/levshina} for discussion). Generative linguists\is{generative linguistics} who are concerned with \isi{learnability} issues generally assume that what can be represented can also be learned, so that there is no distinction between representational constraints and what can be learned. This type of constraint is mentioned here only in passing, for the sake of completeness. It will play no role in what follows.


\section{Two ways in which causal explanations involve diachrony}\label{sec:haspelmath:3}

The peculiar term \textit{\isi{mutation}al constraint} that I adopt here may raise questions: Is it necessary to use a new term for something that is very straightforward? 

The reason I am using this term here is that the possible alternatives “diachronic constraint” or “diachronic explanation” are not fully clear. First of all, diachronic explanations may simply be explanations of diachronic changes, but here we are concerned with causal factors leading to universals. Second, “diachronic” and “historical” are often used interchangeably (cf. \citegen{Good2008_Intro} term “historical explanation” for what I call \isi{mutation}al explanations), and when we speak about historical explanations, we often mean contemporary idiosyncrasies that are better understood if one knows their origins (e.g. the vowel alternation in \textit{foot/feet} finds a historical explanation in the earlier productive pattern of vowel fronting conditioned by a high vowel in the following syllable). But all of this is irrelevant in the present context, where we are concerned with possible and impossible pathways (and sources) of change.

Most importantly, the term \textit{\isi{mutation}al constraint} is necessary because there are two ways in which causal explanations involve diachrony: synchronic distributions may be diachronically \textsc{determined}, or they may come about by the diachronic \textsc{realization} of preferred outcomes. The term \textit{\isi{mutation}al constraint} highlights the fact that change is seen as a causal factor here, not merely the way in which the cross-linguistic distributions arise. By contrast, when universal tendencies are explained by functional-adaptive\is{adaptation} constraints, diachronic change merely serves to realize the \isi{adaptation}.\label{p:haspelmath:merelyserve} 
It plays an important role, indeed a crucial role, because functional \isi{adaptation} is impossible without change. In this sense, functional-adaptive\is{adaptation} explanations are also diachronic (cf. \citealt{Haspelmath1999_Opt}). But functional-adaptive\is{adaptation} change is not the cause of the \isi{adaptation} – the cause is the facilitation of communication for speaker and hearer. Mutational\is{mutation} constraints are situations where the causal factor resides in the change itself.

Two types of \isi{mutation}al constraints may be distinguished: Source constraints and directionality constraints. Most of the diachronic regularities discussed by \citet{Cristofaro2017} concern constraints on possible sources. The best-known directionality constraint is the irreversibility of \isi{grammaticalization} (\citealt{Haspelmath1999_Irrev}, \citeyear*{ Haspelmath2004_Direction}).\footnote{Mutational\is{mutation} constraints 
\label{fn:haspelmath:mutationalconstraints}
are themselves in need of explanation, of course. I say nothing about this in the current paper, because it is already long and complicated enough. Their explanation could itself be “functional” in some sense (to be made more precise), but it cannot be functional-adaptive\is{adaptation}, because the latter type of explanation (as I understand it here) by definition applies only to language systems, not to changes.} 

Another reason for avoiding the terms “diachronic constraint” or “diachronic explanation” is that they invite a contrast with “synchronic constraint” and “synchronic explanation”. But these terms are themselves very problematic, because they seem to conceive of explanation in noncausal terms. The term “synchrony” has a clear application with reference to an abstract, idealized language system (\iai{de Saussure}’s \textit{langue}), but in \sectref{sec:haspelmath:2.1} I noted that language-particular system regularities should be described in terms of constructions or rules, and that causal constraints cannot play any role in them.\footnote{Of course, in practice linguists often use the terms “synchronic explanation” and “synchronic constraint”, but what they mean is either (i) very general language-particular statements (“descriptive explanations”, \sectref{sec:haspelmath:2.1}), or (ii) representational constraints. The latter are biological limitations, which can hardly be labeled felicitously with the Saussurean \ia{de Saussure} term \textit{synchronic}.} 

Instead of “\isi{mutation}al constraint”, one could use “constraint on change” (as in the title of this paper), but the new term “\isi{mutation}al” is more salient (it can be found more easily in automatic text searches), and since it is more specific, it can be used in new combinations like “\isi{mutation}al explanation” (an explanation in terms of a \isi{mutation}al constraint) or “\isi{mutation}al approach”.

\section{Universals are not explained by recurrent pathways of change, only by constraints on change}\label{sec:haspelmath:4}

It has long been known that there are recurrent kinds of changes in phonology (\isi{lenition} of consonants between vowels, \isi{diphthongization} of long vowels, \isi{assimilation}, etc.), and over the last few decades, recurrent changes in morphosyntax have become prominent as well, especially changes falling under the broad category of \isi{grammaticalization} (\citealt{Lehmann1982,HeineEtAl1991,BybeeEtAl1994}; and much related work).

\citet{Bybee2006} highlights recurrent or common pathways of change in the \isi{tense}-\isi{aspect} domain (\isi{perfective}s coming from \isi{anterior}s and ultimately from \isi{completive}, \isi{resultative} or movement constructions; \isi{imperfective}s coming from \isi{progressive}s and ultimately from locational\is{locative} or reduplicative\is{reduplication} constructions; and \isi{future}s coming from volitional\is{desiderative} or movement constructions), and makes the claim that "the true universals of language are the mechanisms of change that propel the constant creation and recreation of grammar” (\citealt{Bybee2006}: 179–180).

 
But she does not distinguish clearly between recurrent pathways of change and constraints on possible changes. There is no doubt that the \isi{tense}-\isi{aspect} changes that she discusses are widespread and significant developments, but nobody knows how widespread they are, compared to other possible changes. There are many \isi{perfective}, \isi{imperfective} and \isi{future} markers about whose sources we know little, or markers whose sources do not fit into any of Bybee’s categories. It is true that the recurrence of the changes makes it virtually certain that the similarities are not accidental, but we do not know enough about \isi{tense}-\isi{aspect} developments to assert with confidence that no other sources are possible or likely, nor even that these sources are clearly predominant over other possibilities. 
 
In one passage Bybee asserts that “the diachronic paths present much stronger cross-linguistic patterns than any comparison based solely on synchronic grammars” (\citeyear{Bybee2006}: 180; see also \citealt{Bybee2008}: 169). But her evidence is not sufficient to show this, at least for \isi{tense} and \isi{aspect}, where the pathways of change are highly diverse, and few people would venture a claim that certain kinds of change are impossible or highly unlikely. 
 
In order to explain universal tendencies, one needs to appeal to something that is stronger than “recurrent (or common) pathways of change”, namely \isi{mutation}al constraints, of the type mentioned earlier. Such constraints allow causal explanations of synchronic cross-linguistic distributions, just like functional-adap\-tive\is{adaptation} constraints. In phonological change\is{sound change}, also discussed by Bybee, some common pathways may indeed qualify as \isi{mutation}al constraints: It could well be that changes involving [h] are highly uniform (especially [s]/[x] > [h] > Ø), so that we are dealing with a \isi{mutation}al constraint, not just a recurrent pathway.\footnote{It is true, of course, that there are some really interesting constraints on morphosyntactic change, notably the constraint that \isi{grammaticalization} cannot be reversed \citep{Haspelmath1999_Irrev}. However, such \isi{mutation}al constraints need not give rise to synchronic universal tendencies. Grammaticalization\is{grammaticalization} as such does not result in any universal tendencies, and \citet[§8]{Bybee2006_Univ} is apparently right that the \isi{lenition} of [s] or [x] via [h] to Ø does not give rise to any synchronic universals either.} Since such \isi{mutation}al constraints entail certain synchronic distributions, they qualify as true explanations, and if a synchronic distribution can be explained by a change constraint, it is not “accidental” (as \citealtv{chapters/collins} calls the universal that \isi{adposition} order correlates\is{word-order correlation} with verb–\isi{object} order).\footnote{It could be that Collins thinks that only representational or functional-adaptive\is{adaptation} constraints can explain synchronic universals, or it could be that he does not think that the sources of \isi{adposition}s are sufficiently constrained. See the next paragraph for more on that possibility.}
 
At this point it is reasonable to ask how one can distinguish in practice between recurrent pathways and \isi{mutation}al constraints. The way to distinguish between synchronic cross-linguistic regularities and recurrent patterns is by gathering representative world-wide data samples (\sectref{sec:haspelmath:2.2}), and in principle, one would have to do the diachronic counterpart in order to establish a \isi{mutation}al constraint. As \citeauthor{chapters/collins} (\citeyear{chapters/collins} [this volume]: \pageref{pg:collins:refforhaspelmath}) puts it, “we need large databases of attested grammaticalisation\is{grammaticalization} pathways”. This is not very practical, however, as there are few solidly attested cases of \isi{grammaticalization}, mostly from European (and a few Asian) languages, and most of what we think we know about general change patterns is based on indirect inferences and cannot be subjected to statistical testing the way this is possible with synchronic patterns. Thus, in practice, linguists rely on their general experience when making judgments, or they cite a range of examples to persuade their colleagues. This method is much less rigorous than the study of synchronic regularities, but it seems to be uncontroversial to assert that in general, both types of diachronic regularities exist: \isi{mutation}al constraints (where a particular outcome has no other possible source), and recurrent changes. This is all I want to argue for in this paper, and I make no strong claims about particular instances (e.g. whether \isi{adposition}s are constrained to arise only from possessed nouns\is{possessive construction} and \isi{transitive} verbs, or whether these are merely recurrent sources).
 

\section{Multi-convergence can only be explained by functional-adaptive constraints}\label{sec:haspelmath:5}

Since \isi{mutation}al constraints are one possible source of synchronic universals, it could be that in fact all synchronic universals are due to \isi{mutation}al constraints of one kind or another, and that functional-adaptive\is{adaptation} and representational constraints are not needed. This is a fairly radical position, but \citet{Cristofaro2017} comes close to adopting it.

Perhaps the strongest reason to believe that we also need functional-adaptive\is{adaptation} explanation is that there are many cases of multi-\isi{convergence}, i.e. situations in which a uniform result comes about through diverse pathways of change that yield a very similar result. For example, I note in \citet{Haspelmath2017} that \isi{inalienable} adpossessive constructions\is{possessive construction} tend to have shorter coding or zero\is{zero marking}, whereas \isi{alienable} adpossessive constructions have overt or longer coding, and I also observe that these patterns can come about in different ways. The \isi{inalienable} pattern may be shorter because of special shortening, or it may be shorter because only the \isi{alienable} pattern got a special new marker. \citet[37]{Kiparsky2008} makes a very similar argument against \citegen{Garrett1990} explanation of \isi{split ergativity} in \isi{mutation}al terms, noting that “[Garrett’s] historical account is insufficiently general [...] because the phenomenon to be explained has several historical sources”.

Interestingly, two of the advocates of \isi{mutation}al explanations of universal tendencies observe the heterogeneity of the pathways themselves. \citet{Anderson2016} is concerned with \isi{case}-marking patterns in \isi{perfective} and \isi{imperfective} \isi{aspect}s across languages, and \citet{Cristofaro2017} is concerned with the \isi{coding asymmetry} of zero \isi{singular}s and overt \isi{plural}s:


\begin{quote}
As it happens, common sources for a new \isi{perfective}, on the one hand, and for a new \isi{imperfective}, on the other, converge on similar patterns of \isi{split ergativity}, although they are quite unrelated to each other. (\citealt{Anderson2016}: 23; cf. also \citealt{Anderson1977})
\end{quote}

\begin{quote}
Different instances of the same configuration can also be a result of very different processes. For example, phonological erosion\is{phonetic reduction}, meaning transfer from a \isi{quantifier} to an accompanying element, and the \isi{grammaticalization} of \isi{distributive}s into \isi{plural} markers can all give rise to a configuration with \isi{zero marking} for \isi{singular} and overt marking for \isi{plural}, yet they do not obviously have anything in common. (\citealt{Cristofaro2017}: 18–19)
\end{quote}

\noindent \iai{Anderson} and \iai{Cristofaro} are thus aware of the multi-\isi{convergence} patterns, but for some reason they do not draw the conclusion that we need an additional causal factor to explain the \isi{convergence} – and as far as I can see, this factor can only be a functional-adaptive\is{adaptation} constraint.\footnote{In principle, it could also be a representational constraint (i.e. \isi{Universal Grammar}), but since the patterns involve \isi{implicational universal}s, this would be difficult to argue for. In general, implicational universals cannot be easily explained by representational constraints.}

The \isi{convergence} of diverse processes on a uniform result could conceivably be accidental, but in this case it could not explain a universal tendency, because a universal tendency is by definition non-accidental. A universal tendency still holds if more and more languages are looked at, whereas accidental similarities of the results of diverse processes would not be repeated if more phenomena were considered. On the analogy of biological usage, where “convergent\is{convergence} \isi{evolution}” refers to the independent development of similar traits for adaptive\is{adaptation} reasons, one should probably avoid the term “\isi{convergence}” if one thinks that the similarities are accidental and will not be confirmed by a larger sample. Thus, \iai{Anderson} and \iai{Cristofaro} should think of their observations in terms of coincidental similarity rather than \isi{convergence}.

\section{Functional-adaptive explanations need not specify pathways of change}\label{sec:haspelmath:6}

One point of criticism of functional-adaptive\is{adaptation} explanations is that they do not say how the change comes about. Especially \iai{Bybee} and \iai{Cristofaro} have argued that for a functional explanation of cross-linguistic regularities to be accepted, it must be shown how the functional motivation plays a role in the way in which the resulting patterns comes about.

I agree that the functional motivation must play a role in the way in which the pattern comes about, but I do not agree that the manner in which it influences the change must be identified for a successful explanation. Below are two relevant quotations.

\begin{modquote}{}
[I]n language universals, causal factors are linguistic changes that create particular synchronic states, and the existence of massive cross-language similarity in synchronic states implies powerful parallels in linguistic change. ... the validity of a principle as explanatory can only be maintained if it can be shown that the same principle that generalizes over the data also plays a role in the establishment of the conventions described by the generalization. \citep[352]{Bybee1988}
\end{modquote}

\begin{modquote}
These [functional] explanations ... have mainly been proposed based on the synchronic distribution of the relevant grammatical phenomena, not the actual diachronic processes that give rise to this distribution in individual languages. In what follows, it will be argued that many such processes do not provide evidence for the postulated dependencies between grammatical phenomena, and suggest alternative ways to look at \isi{implicational universal}s in general. \citep[10]{Cristofaro2017}
\end{modquote}

\largerpage
The problem with \iai{Bybee}’s claim is that the changes are seen as causal factors themselves: Bybee does not seem to envisage the possibility of a “pull force” that increases the probability of change toward a particular kind of outcome, without determining the way in which the change comes about. Moreover, she formulates the requirement that one should be able to \textit{demonstrate} that the functional-adaptive\is{adaptation} principle plays a role in the change, but this requirement is too strong. In general, we do not know much about language change and how and why it happens. The primary evidence for functional-adaptive\is{adaptation} explanations is the fit between the causal factor and the observed outcome. If there is a good fit, e.g. if languages overwhelmingly prefer the kinds of \isi{word order}s that allow easy parsing\is{processing} \citep{Hawkins2014_VarEff}, or if they tend to show economical\is{economy} coding of grammatical categories \citep{Haspelmath2008_FreqIcon}, the best explanation is in functional-adaptive\is{adaptation} terms, as long as there is a way for languages to acquire these properties. The latter requirement is always met, as there are no synchronic states which cannot have arisen from other states. Thus, we may not know how exactly the zero \isi{singular}s and overt \isi{plural}s in \ili{Hebrew} (e.g. \textit{sus} ‘horse’, \textit{sus-im} ‘horses’) may have come about, as they are found in much the same way in Proto-\ili{Semitic}, but we know various ways in which \isi{plural}s can arise (\citealt{Cristofaro2013}: §4), so there is no problem in assuming that the functional motivation of economical\is{economy} coding of the \isi{singular} played a role in the development of the contrast.


Cristofaro\label{Haspelmathchapterpageref} is right that when we look at the changes that give rise to apparently functionally motivated distributions, we do not (necessarily) find evidence that the changes were driven by the need to obey the functional constraints, but finding such evidence is not necessary for a successful explanation.
The evidence for the functional motivation does not come from the manner in which the change happened, but from the fit between the motivation and the observed outcomes. If there is a universal tendency, and it can be explained by a universal motivating factor, then that explanation should be accepted unless a better explanation becomes available.

Explanations of regularities in the world-wide distribution of cultural traits often appeal to functional-adaptive factors in adjacent fields as well. For example, anthropologists sometimes explain religion by prosociality, or monogamy by group-beneficial effects (e.g. \citealt{PaciottiEtAl2011,HenrichEtAl2012}). The issue here is whether better explanations are available, not whether there is a way for religion or marriage to develop. We know little about how religion and marriage first arose or generally arise in societies, and it is very difficult to study the diachronic developments. But we can try to correlate structural traits of human societies with other traits and draw inferences about possible causal factors. There is no perceived need in this literature to show that the mechanisms by which religion or monogamy arise must be of a particular type.\footnote{The same is true for adaptive explanations in evolutionary biology: The fact that wings are adaptive can be inferred from the way wings are used by animals, and we do not expect that wings arise in uniform ways (wings of birds, bats and insects have diverse origins and arose by diverse paths of change, whose nature is not relevant to the adaptive explanation).} Basically, when the result is preferred, any kind of change can give rise to the result, and we do not need to understand the nature of the change, let alone show that the change was motivated by the result.

\largerpage
Another striking example from linguistics is the shortness of frequent words, which is surely adaptive. But there are quite diverse paths to shortness. According to \citet{Zipf1935}, shorter words are shorter because they underwent \isi{clipping} processes (e.g. \textit{laboratory} > \textit{lab}), and according to \citet[12]{Bybee2007}, short words are short because “high-\isi{frequency} words undergo reductive changes at a faster rate than low-\isi{frequency} words […] the major mechanism is gradual phonetic reduction”. But actually in most cases, rarer words are longer because they are (originally) complex elements, consisting of multiple morphs, e.g. \textit{horse vs. hippopotamus}, \textit{car vs. cabriolet}, \textit{church vs. cathedral.} Drastic shortening of longer words seems to occur primarily in the modern age with its large \isi{number} of technical and bureaucratic innovations, but even here, \isi{clipping} is only one of many possibilities; for example, \citet{RonnebergerSibold2014} discusses a \isi{number} of fairly diverse “shortening techniques” in \ili{German}. What unites all of these processes is only one feature: the outcomes of the changes, which are functionally adapted.


When \citet[297]{Cristofaro2014} writes that “any model of the principles that lead to the use of particular constructions […] should take into account the diachronic development of these constructions, rather than just their synchronic distribution”, I certainly agree, because I think that the diachronic developments can illuminate the functional \isi{adaptation}, and a close study of whatever we can learn about diachrony can tell us whether any \isi{mutation}al constraints might play a role. But when there is strong evidence for a universal tendency and there is a good functional-adaptive\is{adaptation} explanation available, the diachronic evidence is not strictly speaking necessary.\label{p:haspelmath:strictlyspeakingnecessary}

\section{A cost scale of constraints}\label{sec:haspelmath:7}

What are we to do when there are several possible explanations, using different kinds of causal factors? For example, what do we do when \isi{word-order correlation}s can be explained either by functional \isi{adaptation} (\isi{processing} \isi{efficiency}, \citealt{Hawkins2014_VarEff}) or by \isi{mutation}al constraints? Or when \isi{case}-marking splits can be explained either by \isi{Universal Grammar} (\citealt{Kiparsky2008}: §2.3) or by \isi{efficiency} of coding?

  The answer is that there is a \textsc{cost scale} of constraints: 

\eabox{\label{ex:haspelmath:3}

\begin{tikzpicture}
     \node(lc){less costly};
     \node[right = 7cm of lc] (mc)  {more costly};
      \draw[<->] (lc) -- (mc);
 \node[below = 3mm of lc,anchor=west,xshift=-5mm]{\isi{mutation}al > functional-adaptive > representational constraints};
\end{tikzpicture}
\vspace{-5mm}
}

The “cheapest” type of explanation is the mutational mode, because language change can be observed, and if we find that certain changes simply do not occur (for whatever reason), we do not need to make more far-reaching claims. Thus, \citet[111]{Bybee2010} discusses the Greenbergian \isi{word order} correlations and notes that “\isi{grammaticalization} gives us the correct orders for free” – a formulation that reflects the assessment that mutational constraints do not involve any additional “cost”.\footnote{Cf. also the similar argumentation in \citet[33]{Kiparsky2008}, in connection with a different phenomenon (involving reflexives): “That is really all that needs to be said […] The historical explanation covers the data perfectly.” I completely agree with Bybee and Kiparsky in this respect.}

The next type of explanation on the scale appeals to functional-adaptive\is{adaptation} constraints. These are more costly because we cannot observe their effects directly and have to rely heavily on inference. But they are less costly than representational constraints, because they are far more general, applying also in other domains of \isi{cognitive} \isi{processing} and communication, often also in nonhuman animals. Again, this is not really controversial: In his chapter on \isi{Universal Grammar}, \citet[79]{Jackendoff2002} says that “we should be conservative in how much linguistic structure we ascribe to an \isi{innate} UG\is{Universal Grammar}. We should welcome explanations of linguistic universals on more general \isi{cognitive} grounds.”

It is only when we observe a cross-linguistic regularity that cannot be explained either by \isi{mutation}al constraints or by functional-adaptive\is{adaptation} constraints that we need to appeal to representational constraints. These involve the most specific (and thus most costly) mechanism, which should only be invoked as a last resort.

\section{Conclusion}\label{sec:haspelmath:8}

In this paper I have argued that cross-linguistic regularities may be explained either by \isi{mutation}al constraints or by functional-adaptive\is{adaptation} constraints (or perhaps by representational constraints, as in generative grammar\is{generative linguistics}) (\sectref{sec:haspelmath:2}). Both kinds of explanations involve diachrony, but in different ways: Mutational\is{mutation} constraints are constraints on possible sources or pathways of change, while functional-adaptive\is{adaptation} constraints influence the results of changes (\sectref{sec:haspelmath:3}). In order to explain a universal tendency, we need to appeal to \isi{mutation}al constraints; merely noting a frequent pathway of change is not enough (\sectref{sec:haspelmath:4}). We can be sure that a cross-linguistic regularity is due to a functional-adaptive\is{adaptation} rather than a \isi{mutation}al constraint if there are diverse pathways of change which converge\is{convergence} on a single result (\sectref{sec:haspelmath:5}). The functional-adaptive\is{adaptation} constraint must influence language change in such a way that change in a particular direction becomes more likely, but this need not be visible in the change itself (\sectref{sec:haspelmath:6}). But when we have good reasons to think that there is a \isi{mutation}al constraint, it takes precedence over functional-adaptive\is{adaptation} and representational explanations (\sectref{sec:haspelmath:7}).

Thus, the answer to the question in the title of this paper (“Can cross-linguistic regularities be explained by constraints on change?”) is: Yes, some regularities can apparently be explained in this way, but clearly not all of them. There remains an important role for functional-adaptive\is{adaptation} constraints in explaining language universals.

\section*{Acknowledgement}

The support of the European Research Council (ERC Advanced Grant 670985, Grammatical Universals) is gratefully acknowledged. 

\sloppy
\printbibliography[heading=subbibliography,notkeyword=this] 
 
\end{document}