\documentclass[output=paper]{langsci/langscibook} 
\author{Martin Haspelmath\affiliation{MPI-SHH Jena \& Leipzig University}}
\title{Can cross-linguistic regularities be explained by constraints on change?}
\abstract{This paper addresses a recent trend in the study of language variation and universals, namely to attribute cross-linguistic patterns to diachrony, rather than to other causal factors. This is an interesting suggestion, and I try to make the basic concepts clearer, by distinguishing clearly between language-particular regularities, universal tendencies, and mere recurrent patterns, as well as four kinds of causal factors (preferences, constraints, restrictions). I make four claims: (i) Explanations may involve diachrony in different ways; (ii) for causal explanations of universal tendencies, one needs to invoke mutational constraints (change constraints); (iii) in addition to mutational constraints, we need functional-adaptive constraints as well, as is clear from cases of multi-convergence; and (iv) successful functional-adaptive explanations do not depend on understanding the precise pathways of change.
}
\begin{document}
\maketitle 

\title{{Can cross-linguistic} regularities be explained by constraints on change?}

 
 

\section{Language universals: Constraints on cross-linguistic distributions as explananda}

Since \citet{Greenberg1963}, it has been widely recognized that comparison of languages with world-wide scope can give us not only taxonomies (as in earlier typology, e.g. \citealt{Schlegel1808,Schleicher1850}: 5–10; \citealt{Sapir1921}), but intriguing limits on cross-linguistic distributions: Especially when one looks at several parameters simultaneously, not all logically possible types are attested, or some types are far more common and others far less common than would be expected by chance. We would like to know why – or in other words, we are looking for causal explanations.

Since \citet{Chomsky1981} at the latest, many generative grammarians have also been interested in cross-linguistic regularities, and have often interpreted them as following from innate principles of universal grammar (UG) and their parametric variation. Others have tended to prefer functional explanations of universals (e.g. \citealt{Comrie1989,Stassen1985,Dixon1994,Dik1997,Hawkins2014_VarEff}), but these authors have likewise appealed primarily to general principles of language and sometimes have even adopted the term “universal grammar” (\citealt{KeenanComrie1977,FoleyVanValin1984,Stassen1985}).

In contrast to these two dominant approaches of the 1970s–1990s, there is an alternative view, according to which the explanation for universals of language structure comes from diachrony. The first well-known author in this tradition is \citet{Greenberg1969}, who stated that “[s]ynchronic regularities are merely the consequence of [diachronic] forces” (1969: 186). A straightforward example of the explanatory role of diachrony is the generalization that languages with prepositions, the possessor generally follows the possessed noun, while in languages with postpositions, it generally precedes it (\citegen{Greenberg1963} Universal 2; \citealt{Dryer1992}). This can be explained on the basis of the diachronic regularity that new adpositions generally arise from possessed nouns in processes of grammaticalization (\citealt{Lehmann1982}[2015]: §3.4.1; \citealt{Bybee1988}: 353–354; \citealt{Collins2019tv,Dryer2019tv} [both in  this volume]). For example, English \textit{because (of)} comes from \textit{by + cause (of)}. Since the order of the elements remains stable in grammaticalization, it is explained that the possessed noun and the adposition tend to occur in the same position in languages.

The view that the explanation of language universals (at least sometimes) comes from diachrony has apparently been gaining ground over the last decade and a half. The early papers by Greenberg (1969; 1978) and \citet{Bybee1988} represented minority views (though \citet{Givón1979} and \citet{Lehmann1982} discussed diachronic change extensively and contributed to giving it a prominent place in functional-typological linguistics). Prominent papers in this vein in more recent years are \citet{Aristar1991}, Anderson (2005; 2008; 2016), Cristofaro (2012; 2013; 2014), \citet{Creissels2008}, \citet{GildeaZúñiga2016}, and in phonology, \citet{Blevins2004} is a book-length study that adopts a similar approach (see also \citealt{Blevins2006}). The following are a few key quotations from some of these papers (and from some others):

\ea
  \ea  “The question for typology is perhaps not what kinds of system are possible, but what kinds of change are possible.” \citep[195]{Timberlake2003}
  \ex “recurrent synchronic sound patterns are a direct reflection of their diachronic origins, and, more specifically, ... regular phonetically based sound change is the common source of recurrent sound patterns” (\citealt{Blevins2006}: 119–120)
  \ex  “statistical universals are not really synchronic in nature, but are rather the result of underlying diachronic mechanisms that cause languages to change in preferred or ‘natural’ ways” (\citealt{BickelEtAl2015}: 29)
  \ex “there are no (or at least very few) substantive universals of language, and the regularities arise from common paths of diachronic change having their basis in factors outside of the defining properties of the set of cognitively accessible grammars” \citep[11]{Anderson2016}
  \z
\z

This paper has two major goals: First, I would like to contribute to conceptual clarification, sorting out what kinds of claims have been made and what terms have been used for which kinds of phenomena (§2).

Second, I argue that there are two ways in which diachrony and universals may interact: Some cross-linguistic generalizations are due to change constraints, as envisaged by the authors in (1), but others are due to functional-adaptive constraints. More specifically, I want to make four points:

\begin{itemize}
\item The notion of “diachronic explanation” is too vague, because explanations may involve diachrony in rather different ways (§3).
\item Universal tendencies cannot be explained by common pathways of change, only by change constraints, or what I call mutational constraints (§4).
\item Multi-convergence clearly shows that functional-adaptive constraints are needed in order to explain at least some cross-linguistic regularities (§5).
\item Functional-adaptive explanations do not depend on understanding the pathways of change, though knowing about the pathways illuminates the explanations (§6).
\end{itemize}

Before arguing for these four points, I will discuss some technical terms in the next section, because there is often confusion between terms for language-particular regularities (§2.1), cross-linguistic regularities (§2.2), and causal factors (§2.3).

\section{Regularities and causal factors: Concepts and technical terms}\label{sec:haspelmath:2}

General terms such as \textit{restriction, constraint, preference, tendency, bias,} and \textit{motivation} have been used in diverse and sometimes confusing ways by linguists. This section clarifies how these terms are used in the present paper, noting along the way what other meanings some of them have been given and what other terms have been used for (roughly) the same concepts. I distinguish between terms for regularities and terms for causal factors, and within the terms for regularities, I distinguish between language-particular and cross-linguistic regularities.

\subsection{Language-particular regularities}\label{sec:haspelmath:2.1}

Regularities within a particular language can concern language use or the conventional language system. Regularities of language use are increasingly studied by corpus linguistics, and they are often thought to be at the root of system regularities, especially in what is often called a “usage-based” view \citep{Bybee2010}. However, regularities of use and system regularities are conceptually different, and linguists normally distinguish clearly between \textit{parole} (language use) and \textit{langue} (language system). In what follows, I focus on the systems of linguistic conventions.

For regularities within language systems, linguists normally use the general terms \textit{rule} and \textit{construction} (or \textit{schema}). In addition, descriptive linguists use many other well-established class (or category) terms like \textit{clause}, \textit{noun phrase}, \textit{suffix}, \textit{dative case}, or terms for relations between constructions such as \textit{alternation} or \textit{derivation}. All of these relate to systems of particular languages.

The term \textit{constraint} is sometimes applied to language-particular regularities, e.g. in constraint-based formalisms such as HPSG, and optimality theory of course also uses constraints for language-particular regularities. However, I will use this term exclusively for causal factors, as explained in §2.3 below.

Language-particular regularities can also be seen as “explanations”, at least in the weak sense that they answer why-questions about lower-level regularities (“Why is there a Dative case on the object of this sentence? Because the verb’s valency requires a Dative.”). Statements of rules or constructions may thus be called “descriptive explanations” if one wishes. In this paper, however, I focus on causal explanations that help us explain the conventional systems of languages themselves.

\subsection{Cross-linguistic regularities: Recurrent patters and universal tendencies}\label{sec:haspelmath:2.2}


Cross-linguistic regularities are typically generalizations over language-particular regularities,\footnote{However, comparative corpus linguistics studies comparable corpora of language use, so there is no necessary connection between cross-linguistic comparison and the study of systems (as opposed to use).} and I will distinguish two kinds of regularities here. On the one hand, similar phenomena may be found in different parts of the world, e.g. ejective consonants, or high vowel epenthesis, or optative mood forms, or functive markers \citep{Creissels2014}. These are called \textsc{recurrent patterns}. On the other hand, some regularities are so strong that we call them \textsc{universals}, because they occur with much greater than chance frequency. I also often use the term \textsc{universal tendencies}, because there is no claim that there are no exceptions.\footnote{Another term for a cross-linguistic distribution is \citegen{Bickel2013} family bias, which means ‘preponderance within a family’. Note that this use of \textit{bias} is quite different from the more common use as in \textit{cognitive bias} (e.g. \citealt{TverskyKahneman1974}); a term like \textit{family tendency} would probably be more transparent.}

Recurrent patterns are not accidental similarities, in the sense that there must be something in the human condition that makes it possible for very similar linguistic categories to appear independently in languages that have no historical connection. However, the discovery of a recurrent pattern does not imply a claim about further languages.

By contrast, the discovery of a universal implies a claim about all other languages: If a universal holds (i.e. is found with much greater than chance frequency in a reasonably representative sample), it is claimed that it also holds in any other representative sample. Thus, universal tendencies are claims that can be tested by examining data from the world’s languages, while recurrent patterns can only be strengthened by additional further observations, but neither confirmed nor disproven by additional data. 

Universal tendencies need to be distinguished, in particular, from family-specific or region-specific trends, so they need to be based on a world-wide sample. A well-known example is the finding that in all major world regions, languages with OV order tend to have postpositions, and languages with VO order tend to have prepositions (\citealt{Greenberg1963}: Universal 2; \citealt{Dryer1992}: 83), even though many languages are exceptions. Another universal tendency is the limitation of nominal suppletion to the most frequent nouns \citep{Vafaeian2013}, even though many languages do not have nominal suppletion at all. We may even identify universal tendencies within patterns that are quite rare, e.g. universals of infixation \citep{Yu2007}, because universal tendencies can be implicational (“If a language has infixation, then...”).

Recurrent patterns, by contrast, are not associated with any kind of quantitative claim, so they could be called \textit{frequent patterns}, or \textit{sporadic patterns}, depending on one’s subjective assessment of their frequency. They are no doubt important for a complete account of human language, but they will be left aside in what follows, as it is not clear what causal factors might illuminate them.

\subsection{Causal factors: Preferences, constraints, restrictions}\label{sec:haspelmath:2.3}


In addition to documenting language-particular systems and cross-linguistic distributions, we also want to know what might explain the distributions in causal terms. The explanatory devices are called \textit{causal factors,} or \textit{(system-external) motivations}, or \textit{constraints}. Especially the latter term is short and relatively clear, so I will use it as the default term for a causal factor. (Two other terms that are used commonly as well, especially outside core linguistics, are \textit{force} and \textit{pressure}. It seems that all these terms are basically synonymous.)

If a constraint is very strong, it can also be called \textit{restriction}, and if it is weaker, it can be called \textit{preference.}\footnote{Another term for system-external causal factors is \textit{bias}, which is used in particular by psychologists for cognitive preferences. Typical biases seem to be quite weak, so that even detecting them is an important part of research. By contrast, linguists’ constraints are often very strong, and controversy concerns primarily the nature (functional-adaptive, representational, mutational) and the interaction of the constraints.} This seems to be in line with much current usage in linguistics. There is thus no objective difference between restrictions, constraints and preferences, and we could use one of the three terms for all types of constraints. (This situation is similar to the cases of sporadic and frequent patterns, which are subjective sub-cases of recurrent patterns.)

Depending on the way in which they affect cross-linguistic distributions, here I distinguish four types of constraints (or restrictions, or preferences), which can be briefly characterized as in \REF{ex:haspelmath:2}.

\ea\label{ex:haspelmath:2} 
  \ea \textit{functional-adaptive constraints}: what facilitates communication (including processing) for speakers and hearers
  \ex   \textit{representational constraints}: what is innately preferred or necessary in the cognitive representation of language
  \ex   \textit{mutational constraints}: what is preferred or necessary in language change (= change constraints)
  \ex   \textit{acquisitional constraints}:  what is preferred or necessary in acquisition by children
  \z
\z

\textsc{Functional-adaptive constraints} are the kinds of factors that have been invoked by functionalists to explain cross-linguistic distributions (e.g. \citealt{Tomlin1986,Malchukov2008,Hawkins2014_VarEff}; among many others). For example, phonological inventories favour five-vowel systems because these make the best use of the acoustic space (\citealt{DeBoer2001}), and case systems favour overt ergatives for low-prominence nominals and overt accusatives for high-prominence nominals because of the association between roles and prominence status \citep{Dixon1994}. These constraints are called \textit{functional-adaptive} rather than merely \textit{functional} to emphasize their role in explaining systems, not usage (the functioning of language). Functional linguists often focus on understanding the functioning of language in usage, but here my interest is in explaining how systems come to have properties that facilitate communication.\footnote{Another term for functional-adaptive constraint is “naturalness parameter” \citep{DresslerEtAl1987}, and functional-adaptive changes have been called “natural changes”.} \citet{Good2008_Intro} uses the term “external explanation” in roughly this sense (cf. also \citealt{Newmeyer1998}: §3.4), but all four types of constraints are external in that they are not part of the system. (“System-internal explanation” is just another word for general regularities of language-particular systems, cf. \sectref{sec:haspelmath:2.1} above; I do not think that the notion of causality is relevant for such statements, so all causal explanatory factors are external.)

\textsc{Representational constraints} 
\label{p:haspelmath:representationalconstraints}
are the kinds of factors that have been invoked by generativists to explain grammatical universals, as noted in §1. In the principles and parameters framework \citep{Chomsky1981}, they were called the principles of universal grammar. For example, the principles of X-bar theory or binding theory have been regarded as representational constraints, as well as universal features and hierarchies of functional categories (e.g. \citealt{Cinque1999}). The general idea is that “the unattested patterns do not arise as they cannot be generated in a manner consistent with Universal Grammar” \citep{SmithEtAl2018}. Representational constraints are usually regarded as very strong, i.e. as restrictions (and thus universal grammar is said to be \textit{restrictive}; cf. also \citealt{Haspelmath2014_CompSyn}).\footnote{Cognitive linguists have also sometimes invoked representational constraints to explain universals, though these are not referred to as UG. An example might be the idea in \citet{Croft1991} that all event types are modeled on the basic force-dynamic agent-patient event type. This is not very strong, i.e. it is a preference, but apparently a preference having to do with cognitive representations, not with communicative or processing preferences.} However, there is no intrinsic reason why representational constraints could not be weaker preferences, e.g. why there could not be a weak innate preference to put elements into a “Determiner” category (though this possibility is almost never considered by linguists). In \citegen{Good2008_Intro} survey, representational constraints are treated under the label of “structural explanations”, but this term (like “system-internal explanations”) is better reserved for general statements of regularities of language-particular systems.

\textsc{Mutational constraints} (or change constraints) are constraints on possible diachronic transitions or possible diachronic sources, which can have an effect on synchronic distributions. For example, if nasal vowels only ever arise from VN sequences, this explains that all languages with nasal vowels also have nasal consonants, and that nasal vowels are rarer than oral vowels in the lexicon \citep{Greenberg1978_Diachr}. Likewise, if infixes only ever arise by metathesis from adfixes (= prefixes or suffixes), this explains that they only occur in peripheral position \citep[51]{Plank2007}. And if adpositions only arise from nouns in possessor–noun constructions, this explains that their position correlates with the position of possessed nouns, as noted in §1. The notion of mutational constraints is not new (\citealt{Plank2007}: §2 calls them “diachronic laws”), but I introduce a new term here in order to make clear that the causal factor is located within the process of change, rather than diachronic change merely realizing a pattern that is driven by functional-adaptive constraints (see §3 below). One could also frame the contrast between mutational constraints and functional-adaptive constraints in terms of \textit{source-oriented} vs. \textit{result-oriented} factors \citep{Cristofaro2017},\footnote{Informally, instead of talking about “result-oriented factors”, one could also say that functional-adaptive constraints are “pull forces” that attract the variable development into a certain preferred state.} or one could say that mutational constraints locate the causal factors within the \textit{mechanisms} of change \citep{Bybee2006}. These are just alternative ways of saying that cross-linguistic distributions are due to mutational constraints.

Finally, \textsc{acquisitional constraints} are factors that impact the acquisition of language and that have an effect on cross-linguistic distributions. Such constraints are briefly discussed by \citet{Anderson2016}, but they do not seem to play a big role in linguistics (but cf. \citealtv{Levshina2019tv} for discussion). Generative linguists who are concerned with learnability issues generally assume that what can be represented can also be learned, so that there is no distinction between representational constraints and what can be learned. This type of constraint is mentioned here only in passing, for the sake of completeness. It will play no role in what follows.

\section{Two ways in which causal explanations involve diachrony}\label{sec:haspelmath:3}

The peculiar term \textit{mutational constraint} that I adopt here may raise questions: Is it necessary to use a new term for something that is very straightforward? 

The reason I am using this term here is that the possible alternatives “diachronic constraint” or “diachronic explanation” are not fully clear. First of all, diachronic explanations may simply be explanations of diachronic changes, but here we are concerned with causal factors leading to universals. Second, “diachronic” and “historical” are often used interchangeably (cf. \citegen{Good2008_Intro} term “historical explanation” for what I call mutational explanations), and when we speak about historical explanations, we often mean contemporary idiosyncrasies that are better understood if one knows their origins (e.g. the vowel alternation in \textit{foot/feet} finds a historical explanation in the earlier productive pattern of vowel fronting conditioned by a high vowel in the following syllable). But all of this is irrelevant in the present context, where we are concerned with possible and impossible pathways (and sources) of change.

Most importantly, the term \textit{mutational constraint} is necessary because there are two ways in which causal explanations involve diachrony: synchronic distributions may be diachronically \textsc{determined}, or they may come about by the diachronic \textsc{realization} of preferred outcomes. The term \textit{mutational constraint} highlights the fact that change is seen as a causal factor here, not merely the way in which the cross-linguistic distributions arise. By contrast, when universal tendencies are explained by functional-adaptive constraints, diachronic change merely serves to realize the adaptation.\label{p:haspelmath:merelyserve} 
It plays an important role, indeed a crucial role, because functional adaptation is impossible without change. In this sense, functional-adaptive explanations are also diachronic (cf. \citealt{Haspelmath1999_Opt}). But functional-adaptive change is not the cause of the adaptation – the cause is the facilitation of communication for speaker and hearer. Mutational constraints are situations where the causal factor resides in the change itself.

Two types of mutational constraints may be distinguished: Source constraints and directionality constraints. Most of the diachronic regularities discussed by \citet{Cristofaro2017} concern constraints on possible sources. The best-known directionality constraint is the irreversibility of grammaticalization (\citealt{Haspelmath1999_Irrev}; 2004).\footnote{Mutational constraints 
\label{fn:haspelmath:mutationalconstraints}
are themselves in need of explanation, of course. I say nothing about this in the current paper, because it is already long and complicated enough. Their explanation could itself be “functional” in some sense (to be made more precise), but it cannot be functional-adaptive, because the latter type of explanation (as I understand it here) by definition applies only to language systems, not to changes.} 

Another reason for avoiding the terms “diachronic constraint” or “diachronic explanation” is that they invite a contrast with “synchronic constraint” and “synchronic explanation”. But these terms are themselves very problematic, because they seem to conceive of explanation in noncausal terms. The term “synchrony” has a clear application with reference to an abstract, idealized language system (de Saussure’s \textit{langue}), but in §2.1 I noted that language-particular system regularities should be described in terms of constructions or rules, and that causal constraints cannot play any role in them.\footnote{Of course, in practice linguists often use the terms “synchronic explanation” and “synchronic constraint”, but what they mean is either (i) very general language-particular statements (“descriptive explanations”, §2.1), or (ii) representational constraints. The latter are biological limitations, which can hardly be labeled felicitously with the Saussurean term \textit{synchronic}.} 

Instead of “mutational constraint”, one could use the term “constraint on change” (as in the title of this paper), but the new term “mutational” is more salient (it can be found more easily in automatic text searches), and since it is more specific, it can be used in new combinations like “mutational explanation” (an explanation in terms of a mutational constraint) or “mutational approach”.

\section{Universals are not explained by recurrent pathways of change, only by constraints on change}\label{sec:haspelmath:4}

It has long been known that there are recurrent kinds of changes in phonology (lenition of consonants between vowels, diphthongization of long vowels, assimilation, etc.), and over the last few decades, recurrent changes in morphosyntax have become prominent as well, especially changes falling under the broad category of grammaticalization (\citealt{Lehmann1982,HeineEtAl1991,BybeeEtAl1994}; and much related work).

\citet{Bybee2006} highlights recurrent or common pathways of change in the tense-aspect domain (perfectives coming from anteriors and ultimately from completive, resultative or movement constructions; imperfectives coming from progressives and ultimately from locational or reduplicative constructions; and futures coming from volitional or movement constructions), and makes the claim that \emph{“\textup{the} }\textbf{{true universals}}\emph{ \textup{of} \emph{language are the} }\textbf{{mechanisms of change}}\emph{ \emph{that propel the constant creation and recreation of grammar” (\citealt{Bybee2006}: 179–180).}}

 
But she does not distinguish clearly between recurrent pathways of change and constraints on possible changes. There is no doubt that the tense-aspect changes that she discusses are widespread and significant developments, but nobody knows how widespread they are, compared to other possible changes. There are many perfective, imperfective and future markers about whose sources we know little, or markers whose sources do not fit into any of Bybee’s categories. It is true that the recurrence of the changes makes it virtually certain that the similarities are not accidental, but we do not know enough about tense-aspect developments to assert with confidence that no other sources are possible or likely, nor even that these sources are clearly predominant over other possibilities. 
 
In one passage Bybee asserts that “the diachronic paths present much stronger cross-linguistic patterns than any comparison based solely on synchronic grammars” (\citeyear{Bybee2006}: 180; see also \citealt{Bybee2008}: 169). But her evidence is not sufficient to show this, at least for tense and aspect, where the pathways of change are highly diverse, and few people would venture a claim that certain kinds of change are impossible or highly unlikely. 
 
In order to explain universal tendencies, one needs to appeal to something that is stronger than “recurrent (or common) pathways of change”, namely \textbf{{mutational constraints, of the type mentioned earlier. Such constraints allow causal explanations of synchronic cross-linguistic distributions, just like functional-adaptive constraints.} }In phonological change, also discussed by Bybee, some common pathways may indeed qualify as mutational constraints: It could well be that changes involving [h] are highly uniform (especially [s]/[x] > [h] > Ø), so that we are dealing with a mutational constraint, not just a recurrent pathway.\footnote{It is true, of course, that there are some really interesting constraints on morphosyntactic change, notably the constraint that grammaticalization cannot be reversed \citep{Haspelmath1999_Irrev}. However, such mutational constraints need not give rise to synchronic universal tendencies. Grammaticalization as such does not result in any universal tendencies, and Bybee (2006: §8) is apparently right that the lenition of [s] or [x] via [h] to Ø does not give rise to any synchronic universals either.}\textbf{{ Since such mutational constraints entail certain synchronic distributions, they qualify as true explanations, and if a synchronic distribution can be explained by a change constraint, it is not “accidental” (as \citealtv{Collins2019tv} calls the universal that adposition order correlates with verb–object order).}}\footnote{It could be that Collins thinks that only representational or functional-adaptive constraints can explain synchronic universals, or it could be that he does not think that the sources of adpositions are sufficiently constrained. See the next paragraph for more on that possibility.}
 
\textbf{{At this point it is reasonable to ask how one can distinguish in practice between recurrent pathways and mutational constraints. The way to distinguish between synchronic cross-linguistic regularities and recurrent patterns is by gathering representative world-wide data samples (\sectref{sec:haspelmath:2.2}), and in principle, one would have to do the diachronic counterpart in order to establish a mutational constraint. As \citeauthor{Collins2019tv} (\citeyear{Collins2019tv} [this volume]:\pageref{pg:collins:refforhaspelmath}) puts it, “we need large databases of \textbf{{attested grammaticalisation pathways”}}. This is not very practical, however, as there are few solidly attested cases of grammaticalization, mostly from European (and a few Asian) languages, and most of what we think we know about general change patterns is based on indirect inferences and cannot be subjected to statistical testing the way this is possible with synchronic patterns. Thus, in practice, linguists rely on their general experience when making judgments, or they cite a range of examples to persuade their colleagues. This method is much less rigorous than the study of synchronic regularities, but it seems to be uncontroversial to assert that in general, both types of diachronic regularities exist: mutational constraints (where a particular outcome has no other possible source), and recurrent changes. This is all I want to argue for in this paper, and I make no strong claims about particular instances (e.g. whether adpositions are constrained to arise only from possessed nouns and transitive verbs, or whether these are merely recurrent sources).} }
 

\section{Multi-convergence can only be explained by functional-adaptive constraints}\label{sec:haspelmath:5}

Since mutational constraints are one possible source of synchronic universals, it could be that in fact all synchronic universals are due to mutational constraints of one kind or another, and that functional-adaptive and representational constraints are not needed. This is a fairly radical position, but \citet{Cristofaro2017} comes close to adopting it.

Perhaps the strongest reason to believe that we also need functional-adaptive explanation is that there are many cases of multi-convergence, i.e. situations in which a uniform result comes about through diverse pathways of change that yield a very similar result. For example, I note in \citet{Haspelmath2017} that inalienable adpossessive constructions tend to have shorter coding or zero, whereas alienable adpossessive constructions have overt or longer coding, and I also observe that these patterns can come about in different ways. The inalienable pattern may be shorter because of special shortening, or it may be shorter because only the alienable pattern got a special new marker. \citet[37]{Kiparsky2008} makes a very similar argument against \citegen{Garrett1990} explanation of split ergativity in mutational terms, noting that “[Garrett’s] historical account is insufficiently general [...] because the phenomenon to be explained has several historical sources”.

Interestingly, two of the advocates of mutational explanations of universal tendencies observe the heterogeneity of the pathways themselves. \citet{Anderson2016} is concerned with case-marking patterns in perfective and imperfective aspects across languages, and \citet{Cristofaro2017} is concerned with the coding asymmetry of zero singulars and overt plurals:

\begin{quote}
As it happens, common sources for a new perfective, on the one hand, and for a new imperfective, on the other, converge on similar patterns of split ergativity, although they are quite unrelated to each other. (\citealt{Anderson2016}: 23; cf. also \citealt{Anderson1977})
\end{quote}

\begin{quote}
Different instances of the same configuration can also be a result of very different processes. For example, phonological erosion, meaning transfer from a quantifier to an accompanying element, and the grammaticalization of distributives into plural markers can all give rise to a configuration with zero marking for singular and overt marking for plural, yet they do not obviously have anything in common. (\citealt{Cristofaro2017}:18–19)
\end{quote}

Anderson and Cristofaro are thus aware of the multi-convergence patterns, but for some reason they do not draw the conclusion that we need an additional causal factor to explain the convergence – and as far as I can see, this factor can only be a functional-adaptive constraint.\footnote{In principle, it could also be a representational constraint (i.e. universal grammar), but since the patterns involve implicational universals, this would be difficult to argue for. In general, implicational universals cannot be easily explained by representational constraints.}

The convergence of diverse processes on a uniform result could conceivably be accidental, but in this case it could not explain a universal tendency, because a universal tendency is by definition non-accidental. A universal tendency still holds if more and more languages are looked at, whereas accidental similarities of the results of diverse processes would not be repeated if more phenomena were considered. On the analogy of biological usage, where “convergent evolution” refers to the independent development of similar traits for adaptive reasons, one should probably avoid the term “convergence” if one thinks that the similarities are accidental and will not be confirmed by a larger sample. Thus, Anderson and Cristofaro should think of their observations in terms of coincidental similarity rather than convergence.

\section{Functional-adaptive explanations need not specify pathways of change}\label{sec:haspelmath:6}

One point of criticism of functional-adaptive explanations is that they do not say how the change comes about. Especially Bybee and Cristofaro have argued that for a functional explanation of cross-linguistic regularities to be accepted, it must be shown how the functional motivation plays a role in the way in which the resulting patterns comes about.

I agree that the functional motivation must play a role in the way in which the pattern comes about, but I do not agree that the manner in which it influences the change must be identified for a successful explanation. Below are two relevant quotations.

\begin{quote}
[I]n language universals, causal factors are linguistic changes that create particular synchronic states, and the existence of massive cross-language similarity in synchronic states implies powerful parallels in linguistic change. ... the validity of a principle as explanatory can only be maintained if it can be shown that the same principle that generalizes over the data also plays a role in the establishment of the conventions described by the generalization. \citep[352]{Bybee1988}
\end{quote}

\begin{quote}
These [functional] explanations ... have mainly been proposed based on the synchronic distribution of the relevant grammatical phenomena, not the actual diachronic processes that give rise to this distribution in individual languages. In what follows, it will be argued that many such processes do not provide evidence for the postulated dependencies between grammatical phenomena, and suggest alternative ways to look at implicational universals in general. \citep[10]{Cristofaro2017}
\end{quote}

The problem with Bybee’s claim is that the changes are seen as causal factors themselves: Bybee does not seem to envisage the possibility of a “pull force” that increases the probability of change toward a particular kind of outcome, without determining the way in which the change comes about. Moreover, she formulates the requirement that one should be able to \textsc{demonstrate} that the functional-adaptive principle plays a role in the change, but this requirement is too strong. In general, we do not know much about language change and how and why it happens. The primary evidence for functional-adaptive explanations is the fit between the causal factor and the observed outcome. If there is a good fit, e.g. if languages overwhelmingly prefer the kinds of word orders that allow easy parsing \citep{Hawkins2014_VarEff}, or if they tend to show economical coding of grammatical categories \citep{Haspelmath2008_FreqIcon}, the best explanation is in functional-adaptive terms, as long as there is a way for languages to acquire these properties. The latter requirement is always met, as there are no synchronic states which cannot have arisen from other states. Thus, we may not know how exactly the zero singulars and overt plurals in Hebrew (e.g. \textit{sus} ‘horse’, \textit{sus-im} ‘horses’) may have come about, as they are found in much the same way in Proto-Semitic, but we know various ways in which plurals can arise (\citealt{Cristofaro2013}: §4), so there is no problem in assuming that the functional motivation of economical coding of the singular played a role in the development of the contrast.

Cristofaro
\label{Haspelmathchapterpageref}
is right that when we look at the changes that give rise to apparently functionally motivated distributions, we do not (necessarily) find evidence that the changes were driven by the need to obey the functional constraints, but finding such evidence is not necessary for a successful explanation.
The evidence for the functional motivation does not come from the manner in which the change happened, but from the fit between the motivation and the observed outcomes. If there is a universal tendency, and it can be explained by a universal motivating factor, then that explanation should be accepted unless a better explanation becomes available.

Explanations of regularities in the world-wide distribution of cultural traits often appeal to functional-adaptive factors in adjacent fields as well. For example, anthropologists sometimes explain religion by prosociality, or monogamy by group-beneficial effects (e.g. \citealt{PaciottiEtAl2011,HenrichEtAl2012}). The issue here is whether better explanations are available, not whether there is a way for religion or marriage to develop. We know little about how religion and marriage first arose or generally arise in societies, and it is very difficult to study the diachronic developments. But we can try to correlate structural traits of human societies with other traits and draw inferences about possible causal factors. There is no perceived need in this literature to show that the mechanisms by which religion or monogamy arise must be of a particular type.\footnote{The same is true for adaptive explanations in evolutionary biology: The fact that wings are adaptive can be inferred from the way wings are used by animals, and we do not expect that wings arise in uniform ways (wings of birds, bats and insects have diverse origins and arose by diverse paths of change, whose nature is not relevant to the adaptive explanation).} Basically, when the result is preferred, any kind of change can give rise to the result, and we do not need to understand the nature of the change, let alone show that the change was motivated by the result.

Another striking example from linguistics is the shortness of frequent words, which is surely adaptive. But there are quite diverse paths to shortness. According to \citet{Zipf1935}, shorter words are shorter because they underwent clipping processes (e.g. \textit{laboratory} > \textit{lab}), and according to \citet[12]{Bybee2007}, short words are short because “high-frequency words undergo reductive changes at a faster rate than low-frequency words […] the major mechanism is gradual phonetic reduction”. But actually in most cases, rarer words are longer because they are (originally) complex elements, consisting of multiple morphs, e.g. \textit{horse vs. hippopotamus}, \textit{car vs. cabriolet}, \textit{church vs. cathedral.} Drastic shortening of longer words seems to occur primarily in the modern age with its large number of technical and bureaucratic innovations, but even here, clipping is only one of many possibilities; for example, \citet{RonnebergerSibold2014} discusses a number of fairly diverse of “shortening techniques” in German. What unites all of these processes is only one feature: the outcomes of the changes, which are functionally adapted.

When \citet[297]{Cristofaro2014} writes that “any model of the principles that lead to the use of particular constructions […] should take into account the diachronic development of these constructions, rather than just their synchronic distribution”, I certainly agree, because I think that the diachronic developments can illuminate the functional adaptation, and a close study of whatever we can learn about diachrony can tell us whether any mutational constraints might play a role. But when there is strong evidence for a universal tendency and there is a good functional-adaptive explanation available, the diachronic evidence is not strictly speaking necessary.\label{p:haspelmath:strictlyspeakingnecessary}

\section{A cost scale of constraints}\label{sec:haspelmath:7}

What are we to do when there are several possible explanations, using different kinds of causal factors? For example, what do we do when word-order correlations can be explained either by functional adaptation (processing efficiency, \citealt{Hawkins2014_VarEff}) or by mutational constraints? Or when case-marking splits can be explained either by universal grammar (\citealt{Kiparsky2008}: \sectref{sec:haspelmath:2.3}) or by efficiency of coding?

  The answer is that there is a \textsc{cost scale} of constraints:

\ea\label{ex:haspelmath:3} 
     less costly < –––––––––––––– > more costly\\
 mutational constraints > functional-adaptive constraints > representational constraints
\z

The “cheapest” type of explanation is the mutational mode, because language change can be observed, and if we find that certain changes simply do not occur (for whatever reason), we do not need to make more far-reaching claims. Thus, \citet[111]{Bybee2010} discusses the Greenbergian word order correlations and notes that “grammaticalization gives us the correct orders for free” – a formulation that reflects the assessment that mutational constraints do not involve any additional “cost”.\footnote{Cf. also the similar argumentation in \citet[33]{Kiparsky2008}, in connection with a different phenomenon (involving reflexives): “That is really all that needs to be said […] The historical explanation covers the data perfectly.” I completely agree with Bybee and Kiparsky in this respect.}

The next type of explanation on the scale appeals to functional-adaptive constraints. These are more costly because we cannot observe their effects directly and have to rely heavily on inference. But they are less costly than representational constraints, because they are far more general, applying also in other domains of cognitive processing and communication, often also in nonhuman animals. Again, this is not really controversial: In his chapter on universal grammar, \citet[79]{Jackendoff2002} says that “we should be conservative in how much linguistic structure we ascribe to an innate UG. We should welcome explanations of linguistic universals on more general cognitive grounds.”

It is only when we observe a cross-linguistic regularity that cannot be explained either by mutational constraints or by functional-adaptive constraints that we need to appeal to representational constraints. These involve the most specific (and thus most costly) mechanism, which should only be invoked as a last resort.

\section{Conclusion}\label{sec:haspelmath:8}

In this paper I have argued that cross-linguistic regularities may be explained either by mutational constraints or by functional-adaptive constraints (or perhaps by representational constraints, as in generative grammar) (\sectref{sec:haspelmath:2}). Both kinds of explanations involve diachrony, but in different ways: Mutational constraints are constraints on possible sources or pathways of change, while functional-adaptive constraints influence the results of changes (\sectref{sec:haspelmath:3}). In order to explain a universal tendency, we need to appeal to mutational constraints; merely noting a frequent pathway of change is not enough (\sectref{sec:haspelmath:4}). We can be sure that a cross-linguistic regularity is due to a functional-adaptive rather than a mutational constraint if there are diverse pathways of change which converge on a single result (\sectref{sec:haspelmath:5}). The functional-adaptive constraint must influence language change in such a way that change in a particular direction becomes more likely, but this need not be visible in the change itself (\sectref{sec:haspelmath:6}). But when we have good reasons to think that there is a mutational constraint, it takes precedence over functional-adaptive and representational explanations (\sectref{sec:haspelmath:7}).

Thus, the answer to the question in the title of this paper (“Can cross-linguistic regularities be explained by constraints on change?”) is: Yes, some regularities can apparently be explained in this way, but clearly not all of them. There remains an important role for functional-adaptive constraints in explaining language universals.

\section*{Acknowledgement}

The support of the European Research Council (ERC Advanced Grant 670985, Grammatical Universals) is gratefully acknowledged. 

\sloppy
\printbibliography[heading=subbibliography,notkeyword=this] 
 
\end{document}