\documentclass[output=paper]{langsci/langscibook} 
\ChapterDOI{10.5281/zenodo.2583822}
\author{Karsten Schmidtke-Bode\affiliation{Leipzig University and Friedrich Schiller University Jena}\lastand Eitan Grossman\affiliation{Hebrew University of Jerusalem}}
\title{Diachronic sources, functional motivations and the nature of the evidence: A synthesis}
\shorttitlerunninghead{Diachronic sources, functional motivations and the nature of the evidence}
\abstract{In this epilogue, we summarize and reflect on the major threads and arguments from the individual contributions to this volume (\sectref{sec:epilogue:1}), and we also briefly outline some challenges and directions for future work on the topic (\sectref{sec:epilogue:2}).}
\begin{document}
\maketitle 
 
 

\section{The voices of the present volume}\label{sec:epilogue:1}
\largerpage[-1]

Above all, this volume has been concerned with the theoretical status of the historical processes that lead to statistical universals of grammatical structure. In the typological research programme initiated by \iai{Greenberg}, it was recognized from early on that a “dynamic” perspective on universals is vital (e.g. \citealt{Greenberg1969}), and it was also occasionally suggested that the diachronic origins of the structures in question may themselves be able to \textit{explain} current universal patterns (e.g. \citealt{Givón1975,Greenberg1978_Diachr}). 


In the last decade or so, this position appears to have become more popular and to be pursued more systematically, and it is now often explicitly contrasted with the widespread view that universal grammatical patterns reflect adaptations\is{adaptation} to language users’ needs, such as a preference for iconic or efficient grammatical structures. As argued in the lead article to the present volume, this latter position can be characterized as “result-oriented”: Languages develop similar traits by virtue of their users selecting\is{selection} and propagating\is{propagation} more adaptive\is{adaptation} variants over less adaptive\is{adaptation} ones.\footnote{For many readers, the term “result-oriented” will conjure up the notion of \isi{teleology}. But as, for example, \citet{Keller1994} and \citet[64--71]{Croft2000_Change} show, there are many functional-adaptive\is{adaptation} changes that can be interpreted non-teleologically\is{teleology}: They are made in pursuit of individual communicative goals rather than with the intention of changing the distribution of grammatical marking in the language at large.} Accordingly, there is an important diachronic element in this line of explanation, but the individual diachronic processes that bring the synchronic results about “merely serve to realize the \isi{adaptation}” (\iai{Haspelmath}, p. \pageref{p:haspelmath:merelyserve}; see also \citet[266]{Hawkins2004} for a similar formulation). This is the crucial difference from the “source-oriented” approach, in which synchronic typological patterns are explained directly in terms of their source constructions: They are seen as long-term reflections of the particular ways in which each structure originally emerged, and it is argued not only that these “birth processes” do not provide evidence for an overarching functional-adaptive\is{adaptation} force being at work (e.g. \iai{Cristofaro}’s paper), but that there is simply no need to appeal to such forces because the diachronic development produces the synchronic pattern as a natural by-product that persists\is{persistence} into the present time (e.g. \iai{Cristofaro}’s, \iai{Collins}’s and partly also \iai{Dryer}’s and \iai{Diessel}’s contributions). 

The general thrust of source-oriented typology is thus that it can provide an immediate, or “first-level” \citep[1]{Creissels2008}, explanation for synchronic distributions, and \iai{Haspelmath} proposes in his lead \isi{article} that whenever immediate explanations in terms of source constructions are feasible, they should actually be preferred to functional-adaptive\is{adaptation} ones, following a logic similar to \isi{Occam’s Razor}: Immediate explanations are less “costly”, in that no independent evidence for alleged functional principles, and their interaction with possibly overriding forces, has to be adduced. \citet{Cristofaro2014}, for example, suggests that a language without any \isi{case} markers for core arguments may come to develop a specific A-marker by processes of \isi{grammaticalization} (e.g. \isi{instrumental} to \isi{ergative} \isi{reanalysis}); the direct result of this development is a \isi{case} system that retains \isi{zero marking} for S and P. Typologically, such a system thus patterns with others in which one core argument of \isi{transitive} clauses, as well the S argument of \isi{intransitive} clauses, remains unmarked\is{zero marking}. But since the diachronic facts give us this constellation “for free”, in \citegen[111]{Bybee2010_Cogn} words, it would be costlier to summon additional functional-adaptive\is{adaptation} forces to explain the pattern: If one assumes that the above scenario is representative of how \isi{ergative} \isi{case} systems arise in general, there is no need to appeal to overarching discourse-pragmatic similarities between S and P (\citealt{DuBois1987}) or to a general drive for economical\is{economy} \isi{alignment} systems \citep{Comrie1989}. The same logic applies to P-marking systems and, at least in some cases, even to split-intransitive\is{split intransitivity} systems \citep{Creissels2008}.\footnote{Note that Creissels uses the terms “direct” and “indirect” explanation for what is here called result-oriented and source-oriented, respectively. For Creissels, source-oriented accounts are less direct than the functional motivations commonly invoked in typology, but according to \iai{Haspelmath}’s “cost scale” of explanation, it makes sense to say that source-based accounts are actually more direct than result-oriented approaches, as the former lead us directly from the source construction to the present distributions. This is why we called them “immediate” explanations above.} 


Source-based accounts, then, are simultaneously more and less elegant than many functional-adaptive\is{adaptation} motivations: They are composed of individual, partly heterogeneous strands of explanation (\iai{Cristofaro}, p. \pageref{p:cristofaro:strands}), which makes them arguably less elegant than highly general principles like “harmonic \isi{alignment}” \citep{Aissen2003} or “early immediate constituents” \citep{Hawkins1994}, but also perhaps less susceptible to postulating motivations that, in fact, may not apply.\footnote{An example from the present volume is \iai{Diessel}’s critique of (specific aspects of) Hawkins’s \isi{processing} account of the position of subordinating morphemes\is{subordinator}. \iai{Diessel} argues that there is a plausible source-based explanation for these patterns that simply does not need to appeal to overarching \isi{processing} principles.} At the same time, their immediate and hence uncostly way of accounting for universals makes them more economical\is{economy} than functional-adaptive\is{adaptation} explanations. 

But there is a critical issue with accepting such low-cost explanations, which is epistemological in nature: While we have robust evidence for synchronic states – and typological research has produced a number of sophisticated tools for isolating truly universal tendencies in those states from contingencies like geographical and genealogical relatedness (e.g. \citealt{Bickel2013,Bickel2018,JaegerEtAl2011}) – we do not have comparable world-wide evidence for diachronic trajectories and diachronic sources. It is thus inevitable that the data provided by source-oriented typologists are highly biased (to certain well-documented or convincingly reconstructed families), sketchy and, as \citet[3]{Creissels2008} readily admits, often “largely speculative”. As long as we have no way of knowing whether the historical scenarios postulated for a particular domain are typical of that domain or, indeed, exhaust the possibilities by which a given synchronic pattern can arise in that domain, we cannot be sure that the sources provide the best explanation for the synchronic patterns.\footnote{In \iai{Dryer}’s contribution, this point is made with regard to \isi{nominalization}s being the (alleged) major origin of the V–O \& N–Gen correlation\is{word-order correlation}: He argues (against \iai{Collins}) that the diachronic evidence for this scenario is currently too scanty and speculative to be accepted as a valid explanation, and that there are “many [other] ways” (\iai{Dryer}, p. \pageref{p:dryer:manyotherways}) in which this correlation\is{word-order correlation} can come about diachronically.} 
\newpage
This epistemological problem is the basis for \iai{Haspelmath}’s distinction between “recurrent patterns of change” and the much stronger “\isi{mutation}al constraints”; crucially, he claims that it is only the latter that can constitute a genuine explanation for language universals. The \isi{word-order correlation}s described in \iai{Collins}’s (and in the main part of \iai{Dryer}’s) paper may well be due to such \isi{mutation}al constraints: Even in the absence of more balanced historical evidence, the pieces of the diachronic puzzle that we do have suggest that there are very strong restrictions on the possible sources of auxiliaries and adpositions. The fact that the position of these categories correlates with that of their sources may thus be sufficiently explained by diachronic \isi{persistence} effects.\footnote{Though see, e.g., \citet[210--215]{Harris1995_Hist} for important qualifications of this view: It is not always the case that the ordering pattern from the source construction is actually retained in the target construction and, conversely, correlating\is{word-order correlation} orders may come about by processes other than \isi{reanalysis}. We will return to this latter point below.} But in many other cases, especially those involving coding contrasts rather than pairs of linear order, things are not as clear-cut: The pathways we know of are usually more diverse, so the many cases for which we do not have historical data may just as well result from yet other sources and trajectories. And yet the synchronic states they yield are strikingly more uniform than expected by chance, and it is precisely for such situations that \iai{Haspelmath} finds the costlier functional-adaptive\is{adaptation} motivations appropriate.

\largerpage
While the distinction between “recurrent patterns of change” and “\isi{mutation}al constraints” may be very difficult to maintain in practice, it highlights that alternative terms like “diachronic approach” or “diachronic explanation” are actually misleading: Both source- and result-oriented approaches in typology rely fundamentally on diachronic processes, as even result-oriented motivations must somehow be implemented in the developments that produce the synchronic pattern \citep{Haspelmath1999_Opt}. \iai{Haspelmath}’s terminological proposal thus helps to clarify the essence of the contrast, which lies precisely in the theoretical status attributed to diachronic processes in the two approaches. 


At the same time, the opposition of “\isi{mutation}al” and “functional-adaptive”\is{adaptation} constraints makes one wonder whether the former are not also ultimately driven by functional motivations. We will return to this question in more detail in \sectref{sec:epilogue:2} again, but let us still ask at this point how supporters of source-oriented explanations \textit{motivate} the kinds of diachronic developments they discuss: They clearly argue against functional-adaptive\is{adaptation}, i.e. result-oriented, motivations in \iai{Haspelmath}’s sense, but they neither claim that diachronic processes are entirely accidental,\footnote{This even holds for \iai{Collins}’s contribution, who claims that “some universals are historical \textit{accidents}” (p. \pageref{p:collins:historicalaccidents}): He uses the term “accidental” as an anto\-nym of “functional-adaptive”\is{adaptation}, but not as a synonym of “random” or “chaotic”.} nor that they are triggered by \isi{innate} “representational constraints” (in \iai{Haspelmath}’s terms).\footnote{Because of the latter, the debate in the present book – in contrast to earlier volumes on the \isi{topic} (e.g. \citealt{Hawkins1988_ExplEd,Good2008_Change}) – takes place entirely within the non-generative\is{generative linguistics}, i.e. usage-based\is{usage-based approach}, camp.} It seems to us that source-oriented explanations chiefly make reference to online processes of \isi{categorization} and inferencing\is{inference} \citep{Bybee2010}, which can lead to the \isi{reanalysis} of the form-function mappings in a given surface string (\citealt{Croft2000,DeSmet2009}). It is in this way that new grammatical markers (e.g. \isi{case} or \isi{number} morphemes) as well as new syntactic structures (e.g. Aux–V\is{auxiliary} constructions) “naturally” emerge from pre-existing material, in all languages. To be sure, these diachronic processes work by applying domain-general \isi{cognitive} mechanisms to communicative interactions, so they are \textit{ultimately} motivated in terms of these mechanisms. Crucially, however, the \isi{reanalysis} itself is not adaptive\is{adaptation} in nature: It does not happen in order to produce a more efficient\is{efficiency} coding strategy for, say, \isi{number} or \isi{case}, or to disambiguate\is{ambiguity} the core arguments of \isi{transitive} clauses. This is one of \iai{Cristofaro}’s major arguments for rejecting functional-adaptive\is{adaptation} motivations for \isi{case} and \isi{number} marking (and similar grammatical categories). If anything, then, the major mechanism of grammatical \isi{innovation} in source-based accounts, i.e. \isi{reanalysis}, is itself motivated by whatever perceptual, \isi{cognitive} or communicative factors invite a \isi{reanalysis} in the first place.\footnote{There \phantomsection
\label{fn:epilog:8}
are a number of interesting proposals as to the kinds of context that facilitate or even induce \isi{reanalysis} (e.g. \citealt{DetgesWaltereit2002,HansenWaltereit2006,RosemeyerGrossman2017,SchwenterWaltereit2009,TraugottDasher2002}). To take but one recent example, \citet{Eckardt2009} argues that listeners typically reanalyze\is{reanalysis} utterances in situations of “pragmatic\is{pragmatics} overload”, e.g. utterances whose \isi{presupposition}s are not easily accommodated. In addition, it has also been suggested that reanalysis is sanctioned by the cognitive mechanism of analogy, in that reanalysis is often contingent on a model, or supporting construction, in the language in question (see \citealt{Fischer2011_Analogy}; \citealt{DeSmetFischer2017_Support}).}


\largerpage
But a critical question is whether \isi{reanalysis} is really the only way in which existing morphemes and constructions can give rise to grammatical innovations. Result-oriented approaches allow for the possibility that the agents of such \isi{innovation}s are not exclusively listeners (as in \isi{reanalysis}), but also speakers. In particular, speakers may re-functionalize existing material in precisely those contexts where additional marking is felt to be beneficial for information \isi{processing}. Some of the diachronic scenarios proposed in \iai{Michaelis}’ paper appear to rely on this mechanism: She argues that when possessive\is{possessive construction} \isi{person} forms (e.g. \textit{your}) are employed to express a relatively unusual function, namely reference (\textit{yours}) instead of attribution, speakers summon additional marking to signal this deviation (see also \citealt{Croft1991,Croft2001} for a similar proposal). \citet{ZeevatJäger2002} refer to this functional-adaptive\is{adaptation} recruitment of marking as “\isi{annexation}” or “semantic \isi{epenthesis}”, and they use this mechanism to explain, for example, the rise of differential argument marking\is{differential object marking} (e.g. the \isi{flagging} of \isi{object}s with statistically unexpected referential properties). Whether or not one finds these particular examples convincing, one could – in principle – imagine that some of the diachronic sources of \isi{plural} marking that \iai{Cristofaro} discusses are not due to \isi{reanalysis} either, but go back further, namely to a speaker’s insertion of a lexical marker like ‘all’, ‘people’, etc. in contexts where \isi{plural}ity is relatively unexpected or in need of disambiguation\is{ambiguity} (as in Present-Day \ili{English} \textit{you} \textit{all,} \textit{you} \textit{guys,} etc.); it is only afterwards that such markers get reanalyzed\is{reanalysis} and grammaticalized\is{grammaticalization} as \isi{plural} morphemes, but their ultimate origin may have been a pattern of functional-adaptive\is{adaptation} “\isi{annexation}”.\footnote{In \citegen{Croft2000} systematization of grammatical innovations, a mechanism very similar to \isi{annexation} is actually described as a particular kind of \isi{reanalysis}: In his so-called “\isi{cryptanalysis}”, speakers feel that a conventionalized construction does not code an intended meaning component sufficiently and thus add appropriate material (e.g. double \isi{plural}s like \ili{English} \textit{feet-s} or \ili{Uzbek} \textit{bi-z-lar} ‘we-\textsc{pl}{}-\textsc{pl’}, see also \citealt{Koch1995} for further examples from different grammatical domains). However, all of \iai{Croft}’s examples differ from the above cases in that they already contain an overt grammatical marker that is analyzed as not being present (typically, it seems, as a result of \isi{chunking} and \isi{entrenchment} (\citealt{Bybee2015}: 102ff.)). The notion of \isi{annexation}, by contrast, is intended to capture the \textit{first} kind of grammatical marking that arises (e.g. an \isi{accusative} \isi{case} marker on formerly bare \isi{object} NPs). It is thus not a kind of contextual \isi{reanalysis} of previously existing material, but the recruitment of a marker from another domain.} Therefore, although we will never be able to replay the \isi{innovation} of highly grammaticalized\is{grammaticalization} markers, we should not exclude a priori the possibility that it is driven by processes other than \isi{reanalysis}. 

\largerpage
An immediately related issue is that source-based typologies also tend to be too narrow on another plane: When \iai{Cristofaro} pleads to “take diachronic evidence seriously” (p. \pageref{p:cristofaro:evidenceseriously}), one wonders why her arguments against particular functional motivations revolve entirely around the \isi{innovation} stage of grammatical change, to the exclusion of further developments. The contributions by \iai{Schmidtke-Bode} and by \iai{Seržant} highlight the importance of \isi{diffusion} processes, i.e. the gradual extension of \isi{innovation}s to new environments, and particularly also stages at which the use of a grammatical marker is (still) variable. There is ample evidence from \isi{corpus} data, grammatical descriptions, \isi{psycholinguistic} experimentation and, as \iai{Levshina}’s paper shows, from \isi{artificial language} learning\is{acquisition}, that a significant part of such variability is driven by functional-adaptive\is{adaptation} motivations. Therefore, we believe that a more appropriate way of taking diachronic evidence seriously would be to return to \citegen{Bybee1988} original formulation: Bybee argues that, for functional-adaptive\is{adaptation} explanations to be valid, “it must be shown that the factor appealed to as explanation actually contributes to the creation of the particular grammatical convention” \citep[357]{Bybee1988}. As the creation of a grammatical convention goes well beyond the processes and motivations by which a pattern first arose, the absence of evidence for functional-adaptive\is{adaptation} motivations at the \isi{innovation} stage does not provide evidence for the absence of such motivations in the development of the grammatical pattern in question.

This leads us (back) to the nature of the evidence that is brought to bear on the present discussion. \iai{Haspelmath} adopts the strong position that “diachronic evidence is not strictly speaking necessary” (p. \pageref{p:haspelmath:strictlyspeakingnecessary}) to explain a typological regularity in functional-adaptive\is{adaptation} terms. This radical position appears to stem, at least in part, from the observation that where we do have pieces of diachronic stories, it often seems to be the case that “all diachronic roads lead to the same synchronic Rome” \citep[38]{Kiparsky2008}. In other words, one and the same typological state can arise in manifold ways, which \iai{Haspelmath} (just like Kiparsky) takes as evidence for convergent\is{convergence} \isi{evolution} towards a common \isi{attractor} state. This is perhaps one of the most interesting aspects of the present debate, as exactly the same type of evidence (i.e. the available or reconstructed\is{reconstruction} historical data) is interpreted in opposite ways. \iai{Michaelis}’ contribution endorses the \iai{Haspelmath}–\iai{Kiparsky} stance: the \isi{coding asymmetry} between attributive and referential possessive\is{possessive construction} forms is sometimes due to \isi{phonetic reduction} processes in the more predictable\is{predictability} (i.e. the attributive) function, and often due to the \isi{annexation} and \isi{grammaticalization} of more coding material in the less predictable\is{predictability} (i.e. the referential) function, and again from a variety of different sources. \iai{Cristofaro}, by contrast, argues (for \isi{number} marking) that the phonetic erosion\is{phonetic reduction} of overt \isi{singular}s may have various language-internal motivations, and that the sheer variety of different sources for the \isi{grammaticalization} of new \isi{plural} markers simply does not point towards a single, unifying force. There is no obvious way to settle this issue, given the above-mentioned quantity and depth of resolution of actual diachronic data. This is exactly why proponents of functional-adaptive\is{adaptation} motivations have long sought to triangulate typological data with behavioural evidence from other sources.

Within the confines of the present volume, we have not been able to represent most of these other data sources, but the contributions by \iai{Seržant} and by \iai{Levshina} do highlight the potential of analyzing performance data from historical transition phases and from \isi{artificial language} learning\is{acquisition}, respectively. The latter is a relatively novel experimental paradigm that, despite certain drawbacks (e.g. potential L1 influence), provides a useful addition to classic \isi{psycholinguistic}, \isi{neurolinguistic} and simulative experimentation on typologically relevant phenomena (see, e.g. \citealt{KurumadaJaeger2015,BickelEtAl2015,Lestrade2018} for these different types of data on typological preferences in \isi{case} marking). All of these performance data point to the existence of functional-adaptive\is{adaptation} forces in grammar and hence cannot be neglected in the study of typological patterns. In fact, the recent movement in usage-based\is{usage-based approach} linguistics to view language as an instance of a “complex \textit{adaptive}\is{adaptation} system”\is{complex adaptive system} (e.g. \citealt{Gell-Mann1992,BecknerEtAl2009}) suggests that grammatical structure is shaped over time to adapt\is{adaptation} to interlocutors’ (partially conflicting) needs. 

At the same time, another important property of such complex adaptive\is{adaptation} systems\is{complex adaptive system} is that their developmental trajectories crucially depend on the system’s initial conditions – i.e. precisely on the nature of each “source construction”. This ties in nicely with \iai{Cristofaro}’s (p. \pageref{p:cristofaro:commonalitiesexceptions}) argument that a source-based approach to universals is not only able to capture the cross-linguistic commonalities (because there are, after all, strong preferences in the kinds of \isi{grammaticalization} processes that happen across languages) but also the \isi{exception}s: The latter, she argues, also fall out directly from the initial conditions, in that the languages with exceptional patterns may have different source constructions, or even no sources of the relevant type.\footnote{This argument is also supported by \iai{Diessel}’s contribution: He shows (p. \pageref{p:diessel:exception}) that instances of postposed \isi{adverbial clause}s with final \isi{subordinator}s (‘his going-to-the-movies because’) are unexpected from a \isi{processing} perspective, but receive a natural explanation in diachronic terms if one realizes that these structures exist in OV languages which place the source construction, i.e. \isi{oblique} PPs, in postverbal rather than preverbal position.}  


While this is an attractive (again: “low-cost”) proposal, we feel that it needs to be made more rigorous. At present, source-oriented accounts are often selective in their interpretation of the data. For example, when \iai{Cristofaro} (p. \pageref{p:cristofaro:ergatives}) claims that \isi{ergative}s do not apply to first- and second-\isi{person} \isi{pronoun}s because their \isi{instrumental} source tended not to do so either (for obvious semantic reasons), one wonders why the same kind of restriction does not carry over to similar cases. For instance, \citet[36]{Kiparsky2008} mentions, among quite a few other examples, that when \isi{ablatives} develop from a source with \isi{separative} meaning (‘away from X’), these sources\is{ablative} are often limited to animates\is{animacy} and physical objects, “and yet we don't find \isi{ablative}s with zero allomorphs\is{zero marking} on abstract nouns”. In other words, purely source-based accounts are sometimes too general, as they predict all kinds of restrictions that get levelled as diachrony unfolds. Conversely, they can also be too limited because, as noted by \citet{Kiparsky2008} as well, some synchronic patterns of differential marking are rather difficult to derive from their sources (e.g. \isi{animacy} restrictions on the Genitive\is{genitive} in Yukaghir\il{Yukaghir (Kolyma)}). While \iai{Kiparsky}’s critique was directed chiefly against \citet{Garrett1990}, it seems to us that the same argument applies to more recent incarnations of source-oriented explanations.

\largerpage[2]
This observation rounds off our survey of the arguments laid out in the volume, and we now proceed to some implications from and possible future directions for the debate as a whole.

\section{Lessons, challenges and future directions}\label{sec:epilogue:2}

One important general lesson from \iai{Haspelmath}’s lead article is that the very notion of “diachronic explanation” in typology is too vague, as both source- and result-oriented explanations crucially involve diachronic processes, but in different ways (see \sectref{sec:epilogue:1} above). Furthermore, it is necessary to specify the requirements, as \iai{Haspelmath} does, on when a so-called source-oriented account of universals is considered a genuine explanation, which is precisely what a terminological proposal like “\isi{mutation}al explanation” is meant to capture. But it is less clear to us whether such a \isi{mutation}al explanation is best described as a “constraint” on language, and whether it is as such felicitously juxtaposed with “functional-adaptive”\is{adaptation}, “acquisitional”\is{acquisition} and “representational”\is{Universal Grammar} constraints (\iai{Haspelmath}, p. \pageref{p:haspelmath:representationalconstraints}). The primary reason for this uncertainty is that “\isi{mutation}al constraints”, unlike the others proposed by \iai{Haspelmath}, do not have a clear locus, as it were. The changes they are intended to capture are themselves rooted in forces operating on language users (and thus ultimately on language systems) and these could, in principle, be functional-adaptive\is{adaptation} constraints, constraints on learning\is{acquisition} or constraints on change from \isi{innate} linguistic representations, and possibly others. In other words, “\isi{mutation}al constraints” are always due to something else, something that really constrains the \isi{mutation}s (as \iai{Haspelmath} notes himself (p. \pageref{fn:haspelmath:mutationalconstraints}, fn. \ref{fn:haspelmath:mutationalconstraints})), and so they do not, strictly speaking, form a paradigmatic opposition with these other constraints.
 
To give just one example, \iai{Haspelmath} argues that the universal generalization that all languages with nasal vowels also have nasal consonants can be accounted for directly by the restricted ways in which nasal vowels come about, i.e. most typically by regressive \isi{assimilation} to a following nasal consonant. But this \isi{mutation}al constraint is motivated, at least in part, by processes that one may well describe as “functional”, viz. the anticipation and consequent retiming of articulatory gestures that come with repeated exposure and practice of the VC sequences in question (\citealt{Bybee2015}: 38; but cf. \citealt{Ohala1989,Ohala2003} for alternative explanations). Is this “functional” in the sense of “functional-adaptive”\is{adaptation} (because it \textit{results} \textit{in} easier or more economical\is{economy} articulation for the speaker) or in the sense of being a natural consequence of frequency-based\is{frequency} memory representations\is{cognitive} and our predictions\is{predictability} based on those frequencies? In the latter case, could this possibly count as a “representational\is{cognitive} constraint”? According to \iai{Haspelmath}, it cannot, because the representational constraints he envisages are \isi{innate} linguistic representations (= “costly” stipulations of structure that cannot be explained in more direct terms). But then it is unclear how to classify the \isi{frequency} effects from \isi{exemplar} representations that are not straightforwardly adaptive\is{adaptation} in nature, such as some of the “conserving effects of token \isi{frequency}” discussed in many places by \iai{Bybee} and others (e.g. \citealt{BybeeThompson1997,Pierrehumbert2001,Bybee2001}; see also \citealt{Cristofaro2015} for discussion): Well-entrenched\is{entrenchment} representations are more resistant to change, but that does not necessarily mean that they make speaker-hearer interactions (or a linguistic system) more efficient\is{efficiency} or otherwise better adapted\is{adaptation}.\footnote{Incidentally, \iai{Diessel}’s contribution also distinguishes between “functional” and “\isi{cognitive}” motivations for the development of preposed \isi{adverbial clause}s (p. \pageref{p:diessel:preposedadverbialclauses}). The former relate, for example, to \isi{information structure} and \isi{iconicity}, and are adaptive\is{adaptation} in \iai{Haspelmath}’s sense. The latter refer to the \isi{cognitive} processes involved in the \isi{grammaticalization} of \isi{adverbial clause}s, notably “\isi{automatization}, semantic \isi{bleaching} and formal reduction\is{phonetic reduction}” (p. \pageref{p:xxx:automatization}). Apparently, then, these specific effects of \isi{cognitive} representation are to be kept distinct from “functional” factors, which shows that they do not fit easily into \iai{Haspelmath}’s typology of constraints.}  Similar remarks apply to the pragmatic\is{pragmatics} processes that constrain \isi{reanalysis} (see fn. \ref{fn:epilog:8} above): These are quite systematic and thus principled constraints on the development of languages, yet they are not adaptive\is{adaptation} according to \iai{Haspelmath}’s definition and, therefore, defy classification according to his schema.


A related difficulty pertains to the separation of representational and \isi{acquisition}al constraints (see also \iai{Levshina}’s paper). In generative\is{generative linguistics} approaches, \isi{innate} representations are invoked precisely in order to solve \isi{learnability} problems, making it hard to draw the line between \isi{acquisition} and representation\is{cognitive}. In non-generative\is{generative linguistics} approaches, by contrast, a constraint on \isi{acquisition} only makes sense if it can be disentangled from functional-adaptive\is{adaptation} constraints (cf. “What is functional is learnt best”). And crucially, in both approaches it would have to be shown that processes of language learning\is{acquisition} are causally involved in the diachronic development of languages. While much scepticism has been voiced that (monolingual) L1 \isi{acquisition} should be causally related to language change (see e.g., \citealt{Croft2000,HeineKuteva2007,Diessel2011_Acq} for recent surveys), it is very likely that certain forms of \isi{bilingualism} and L2 \isi{acquisition} play such a causal role, namely in situations of language \isi{contact} (\citealt{Matras2009,MeiselEtAl2013,Gast2017} and many others). But then again, the difficulty remains of separating the \isi{acquisition} processes from either representational or functional-adaptive\is{adaptation} forces involved in them.\footnote{More generally, the issue of language \isi{contact} has received rather little attention in this volume (apart from \iai{Michaelis}’ contribution on \isi{contact} languages, of course). Needless to say, we do not wish to marginalize the role of \isi{contact} for diachronic development. But for one thing, the entire discussion revolves around the notion of universals, which are usually seen as “distilled” properties of linguistic structure after contact-induced similarities are controlled for \citep{Bickel2011_Modelling}. Secondly, as argued above, what happens in \isi{contact} situations deserves its own detailed investigation in order to clearly disentangle different types of forces on diachronic development in these contexts. This may reveal similar pressures on development as in non-\isi{contact} languages (as argued by \iai{Michaelis}) or else point to the overriding importance of other, more contact-specific, factors (e.g. patterns of L2 learning\is{acquisition}, constraints on \isi{borrowing}, etc.). See also \citet{Matras2009} for a book-length survey of these issues, and \citet{Hickey2017} for a state-of-the-art collection on areal linguistics.}

It is beyond the scope of this short epilogue to elaborate on these important issues. The critical point is simply that \iai{Haspelmath}’s constraint typology must be interpreted carefully for what it is, namely a typology of different types of explanation: If we neglect the more elusive \isi{acquisition}al constraints for now, the three remaining “\isi{mutation}al”, “functional-adaptive\is{adaptation}" and “(UG-)\is{Universal Grammar}representational” approaches indeed constitute three very different practices of explaining how universals in language develop. And as such, they can plausibly be ranked on a cost scale which characterizes the number of explanatory principles beyond those that are necessary to explain the origin of each individual construction in one’s sample (\isi{mutation}al > functional-adaptive\is{adaptation} > UG\is{Universal Grammar}-representational). But this does not exhaust what we may wish to call constraints on language, i.e. the sum of all pressures or forces that “cause languages to change in preferred or ‘natural’ ways” (\citealt{BickelEtAl2015}: 29). The different types of explanation rather highlight that either there is or there is not more to the motivation of language universals than the persisting properties of individual source constructions.\footnote{Ultimately, such a typology of constraints on language would have to accommodate, for example, \isi{environment}al factors (humidity, altitude), socio-cultural factors (population size, sociocultural practices, social goals in communication), communicative/pragmatic\is{pragmatics} factors (biases in \isi{inference} making and the resulting utterance interpretation) and \isi{cognitive} factors, with the latter to be worked out more specifically in terms of whether or not they are domain-general abilities or domain-specific biases and to what extent they are \isi{innate} or learned \isi{acquisition}. Some recent systematizations include \citet{ChristiansenChater2008}, \citet{EvansLevinson2009} and \citet{Bybee2010}, but none of them addresses all of the above dimensions (or claims to be exhaustive).} 

Our own view is that \isi{persistence} effects from source constructions are one of many forces which constrain the development of linguistic structure and thus have a role to play in the explanation of universals pertaining to these structures. But as laid out in \sectref{sec:epilogue:1} above, they are rarely ever the whole story. \iai{Seržant}’s contribution to the present volume is particularly insightful in this regard, as he shows that the respective sources of individual differential object markers\is{differential object marking} exert a strong influence on the current use of these markers, but that functional-adaptive\is{adaptation} considerations of efficient\is{efficiency} information \isi{processing} (particularly \isi{ambiguity} avoidance) interact with the source meaning at particular historical stages, and can even pave the way for the further development of the marker in question. So, just as we argued above, each synchronic state of a \isi{complex adaptive system} depends to some extent on its initial conditions; but it is adaptive\is{adaptation} nevertheless. As \citet[263]{Shibatani2006} puts it,\largerpage a language should be seen “as a historically-evolving functional organism sustaining constant pressure for \isi{adaptation}”. 

Therefore, while the present volume sought to encourage a lively debate between, and hence often a rigid juxtaposition of, source- and result-oriented explanations, it seems likely that most typological phenomena will need a nuanced mixture of both (see also \iai{Dryer}’s and \iai{Diessel}’s contributions to this volume). In fact, this echoes an assessment given by \citet[287--288]{Nichols2008_Diach}:


\begin{quote}
Rather than synchronic patterns always being the goal and driving force of language change, various synchronic patterns are the predictable consequences of diachronic processes which have their own logic independent of the synchrony they produce. Thus, to a greater extent than [one might presume], synchronic structural patterns are epiphenomenal. But they are not entirely so. Economies\is{economy} of various kinds appear to be targets of change […], and there appear to be […] structural patterns that may be goals of change but are not its accidental results.
\end{quote}

The methodological challenge ahead is thus to calibrate more precisely, for each grammatical domain and typological generalization at a time, how much room for functional-adaptive\is{adaptation} motivations is left once one controls for \isi{persistence} effects in the data as much as possible. As \iai{Collins} (p. \pageref{p:collins:dependency}) reminds us, constraints inherited from the source add yet another kind of dependency (on top of areal and genealogical relations) to typological samples. It then becomes an empirical question whether the sources are so clearly circumscribed that they, indeed, suggest a \isi{mutation}al explanation and give us the synchronic distributions for free, or whether it is necessary to resort to costlier explanations along functional-adaptive\is{adaptation} lines that go beyond the individual sources.

Another avenue for conceptual work on universals and diachrony would be to expand and flesh out a framework developed by \citet{Greenberg1978_Diachr}, \citet{Nichols1992,Nichols2003} and \citet{Bickel2013}. This framework lays the conceptual foundations for modelling probabilities of cross-linguistic unity and diversity in diachronic terms. For example, according to \citet[76]{Greenberg1978_Diachr}, a particular linguistic phenomenon should be universal or near-universal “if it can arise very frequently and is highly stable once it occurs. [… ] If a particular property rarely arises but is highly stable\is{stability} when it occurs, it should be fairly frequent on a global basis but be largely confined to a few linguistic stocks.” \citet[287--288]{Nichols2008_Diach} further develops such predictions by bringing \isi{contact}-induced phenomena (\isi{borrowing} and substrate influence) and functional-adaptive\is{adaptation} factors (“harmony”, “unmarkedness\is{markedness}”) into the equation. Elaborating on these lines of thinking, one may look at some of the themes of the present volume in the following way (see \citealt{Grossman2016} and \citealt{GrossmanEtAl2018} for more details):

\ea
Types of diachronic influence on language universals\\
  \ea \textsc{source}: frequency of the source construction \citepv{chapters/cristofaro}
  \ex \textsc{type}: frequency of type of change (e.g. assimilatory\is{assimilation} changes are more common than dissimilatory\is{dissmilation} ones). This has rarely been studied on the basis of large samples and for a wider range of phenomena (largely due to the epistemological problems discussed in \sectref{sec:epilogue:1} above), thus constituting a desideratum in typological research.
  \ex \textsc{path}: number of pathways that lead to a particular item type (e.g. \citealt{BybeeEtAl1994} on \isi{tense}-\isi{aspect}-\isi{mood} constructions)
  \ex \textsc{stage}: number of stages necessary to yield a certain outcome (e.g. \citealt{Harris2008})
  \ex \textsc{stability}: inherent \isi{stability} of item type (\citealt{Greenberg1978_Diachr}, \citealt{Nichols2003}) 
  \ex \textsc{diffusability:} likelihood to diffuse through \isi{contact} (\isi{borrowing}, \isi{calquing}, \isi{contact}-induced \isi{grammaticalization})
  \z
\z

Note that (a), (b), (e) and (f) may themselves be causally related to functional-adaptive\is{adaptation} forces. For example, a given phenomenon may be faithfully inherited and hence be diachronically stable\is{stability} precisely because it is adaptive\is{adaptation} in \iai{Haspelmath}’s sense; and it may easily diffuse in language \isi{contact} for the same reason (see also \citealt{Bickel2013,Bickel2017} for the same observations). 
Just as in \citet{Greenberg1978_Diachr}, then, the basic idea is that the more these factors converge, the stronger the cross-linguistic preponderance of the structure in question. In other words, if a property develops from cross-linguistically frequent sources, as a result of common types of change that involve few stages, if there are multiple pathways that lead to it, it is stable once present, and it is likely to diffuse through \isi{borrowing}, this property is predicted to be (nearly) universal. Conversely, a property that involves rare source constructions, rare changes, and so on, is predicted to be cross-linguistically rare or limited areally and/or phylogenetically. Of course, these factors might have varying strengths, and it is a goal of typological research to determine their relative ranking for each case in question. For example, it may be that a property develops often, from multiple and common sources, but if it is inherently unstable – say, due to a strong functional-adaptive\is{adaptation} pressure to eliminate it – then it is predicted to be sporadically attested areally and genealogically. If it is diffusable, then it has a good chance to take root in particular areas. In phonology, for example, this seems to be the case for aspirated fricatives \citep{Jacques2011} and for affricate-rich systems (\citealt{NikolaevGrossman2018}), the latter of which are diachronically unstable\is{stability} unless supported areally. As far as we are aware, Bickel’s (\citeyear{Bickel2011_Modelling,Bickel2013}) \isi{Family Bias Method} has offered the first principled way of incorporating some of these considerations into actual typological methodology (see \iai{Schmidtke-Bode}'s paper for an application). It is to be hoped that such methods, alongside more classic sampling methods with built-in controls for source-related dependencies (as suggested above), will become de rigeur in \isi{future} typological research.

Above all, we hope that the present volume has offered an insight into current ways of thinking about the role of diachronic processes in explaining universal generalizations, and that it has contributed to specifying the arguments, strengths and weaknesses of different positions in that debate.

\sloppy
\printbibliography[heading=subbibliography,notkeyword=this]
\end{document}