\documentclass[output=paper]{langsci/langscibook} 
\author{Karsten Schmidtke-Bode\affiliation{Leipzig University}\lastand Eitan Grossman\affiliation{Hebrew University of Jerusalem}}
\title{Diachronic sources, functional motivations and the nature of the evidence: A synthesis}
\shorttitlerunninghead{Diachronic sources, functional motivations and the nature of the evidence}
\abstract{In this epilogue, we summarize and further reflect on the major threads and arguments from the individual contributions to this volume (§1), and we also briefly outline some challenges and directions for future work on the topic (§2).}

\begin{document}
\maketitle 
 
 

\section{The voices of the present volume}

Above all, this volume has been concerned with the theoretical status of the historical processes that lead to statistical universals of grammatical structure. In the typological research programme initiated by Greenberg, it was recognized from early on that a “dynamic” perspective on universals is vital (e.g. \citealt{Greenberg1969}), and it was also occasionally suggested that the diachronic origins of the structures in question may themselves be able to \textit{explain} current universal patterns (e.g. \citealt{Givón1975,Greenberg1978}). 

In the last decade or so, this position appears to have become more popular and be pursued more systematically, and it is now often explicitly contrasted with the widespread view that universal grammatical patterns reflect adaptations to language users’ needs, such as a preference for iconic or efficient grammatical structures. As argued in the lead article to the present volume, this latter position can be characterized as “result-oriented”: Languages develop similar traits by virtue of their users selecting and propagating more adaptive variants over less adaptive ones.\footnote{For many readers, the term “result-oriented” will conjure up the notion of teleology. But as, for example, \citet{Keller1994} and Croft (2000: 64–71) show, there are many functional-adaptive changes that can be interpreted non-teleologically: They are made in pursuit of individual communicative goals rather than with the intention of changing the distribution of grammatical marking in the language at large.} Accordingly, there is an important diachronic element in this line of explanation, but the individual diachronic processes that bring the synchronic results about “merely serve to realize the adaptation” (Haspelmath, p. \pageref{p:haspelmath:merelyserve}; see also \citet[266]{Hawkins2004} for a similar formulation). This is the crucial difference from the “source-oriented” approach, in which synchronic typological patterns are explained directly in terms of their source constructions: They are seen as long-term reflections of the particular ways in which each structure originally emerged, and it is argued not only that these “birth processes” do not provide evidence for an overarching functional-adaptive force being at work (e.g. Cristofaro’s paper), but that there is simply no need to appeal to such forces because the diachronic development produces the synchronic pattern as a natural by-product that persists into the present time (e.g. Cristofaro’s, Collins’ and partly also Dryer’s and Diessel’s contributions). 

The general thrust of source-oriented typology is thus that it can provide an immediate, or “first-level” \citep[1]{Creissels2008}, explanation for synchronic distributions, and Haspelmath proposes in his lead article that whenever immediate explanations in terms of source constructions are feasible, they should actually be preferred to functional-adaptive ones, following a logic similar to Occam’s Razor: Immediate explanations are less “costly”, in that no independent evidence for alleged functional principles, and their interaction with possibly overriding forces, has to be adduced. \citet{Cristofaro2014}, for example, suggests that a language without any case markers for core arguments may come to develop a specific A-marker by processes of grammaticalization (e.g. instrumental to ergative reanalysis); the direct result of this development is a case system that retains zero marking for S and P. Typologically, such a system thus patterns with others in which one core argument of transitive clauses, as well the S argument of intransitive clauses, remains unmarked. But since the diachronic facts give us this constellation “for free”, in Bybee’s (2010: 111) words, it would be costlier to summon additional functional-adaptive forces to explain the pattern: If one assumes that the above scenario is representative of how ergative case systems arise in general, there is no need to appeal to overarching discourse-pragmatic similarities between S and P (\citealt{DuBois1987}) or to a general drive for economical alignment systems \citep{Comrie1989}. The same logic applies to P-marking systems and, at least in some cases, even to split-intransitive systems \citep{Creissels2008}.\footnote{Note that Creissels uses the terms “direct” and “indirect” explanation for what is here called result-oriented and source-oriented, respectively. For Creissels, source-oriented accounts are less direct than the functional motivations commonly invoked in typology, but according to Haspelmath’s “cost scale” of explanation, it makes sense to say that source-based accounts are actually more direct than result-oriented approaches, as the former lead us directly from the source construction to the present distributions. This is why we called them “immediate” explanations above.} 

Source-based accounts, then, are simultaneously more and less elegant than many functional-adaptive motivations: They are composed of individual, partly heterogeneous strands of explanation (Cristofaro, p. \pageref{p:cristofaro:strands}), which makes them arguably less elegant than highly general principles like “harmonic alignment” \citep{Aissen2003} or “early immediate constituents” \citep{Hawkins1994}, but also perhaps less susceptible to postulating motivations that, in fact, may not apply.\footnote{An example from the present volume is Diessel’s critique of (specific aspects of) Hawkins’ processing account of the position of subordinating morphemes. Diessel argues that there is a plausible source-based explanation for these patterns that simply does not need to appeal to overarching processing principles.} At the same time, their immediate and hence uncostly way of accounting for universals makes them more economical than functional-adaptive explanations. 

But there is a critical issue with accepting such low-cost explanations, which is epistemological in nature: While we have robust evidence for synchronic states – and typological research has produced a number of sophisticated tools for isolating truly universal tendencies in those states from contingencies like geographical and genealogical relatedness (e.g. \citealt{Bickel2013,Bickel2018,JaegerEtAl2011}) – we do not have comparable world-wide evidence for diachronic trajectories and diachronic sources. It is thus inevitable that the data provided by source-oriented typologists are highly biased (to certain well-documented or convincingly reconstructed families), sketchy and, as \citet[3]{Creissels2008} readily admits, often “largely speculative”. As long as we have no way of knowing whether the historical scenarios postulated for a particular domain are typical of that domain or, indeed, exhaust the possibilities by which a given synchronic pattern can arise in that domain, we cannot be sure that the sources provide the best explanation for the synchronic patterns.\footnote{In Dryer’s contribution, this point is made with regard to nominalizations being the (alleged) major origin of the V–O \& N–Gen correlation: He argues (against Collins) that the diachronic evidence for this scenario is currently too scanty and speculative to be accepted as a valid explanation, and that there are “many [other] ways” (Dryer, p. \pageref{p:dryer:manyotherways}) in which this correlation can come about diachronically.} 

This epistemological problem is the basis for Haspelmath’s distinction between “recurrent patterns of change” and the much stronger “mutational constraints”; crucially, he claims that it is only the latter that can constitute a genuine explanation for language universals. The word-order correlations described in Collins’ (and in the main part of Dryer’s) paper may well be due to such mutational constraints: Even in the absence of more balanced historical evidence, the pieces of the diachronic puzzle that we do have suggest that there are very strong restrictions on the possible sources of auxiliaries and adpositions. The fact that the position of these categories correlates with that of their sources may thus be sufficiently explained by diachronic persistence effects.\footnote{Though see, e.g., Harris \& Campbell (1995: 210–215) for important qualifications of this view: It is not always the case that the ordering pattern from the source construction is actually retained in the target construction and, conversely, correlating orders may come about by processes other than reanalysis. We will return to this latter point below.} But in many other cases, especially those involving coding contrasts rather than pairs of linear order, things are not as clear-cut: The pathways we know of are usually more diverse, so the many cases for which we do not have historical data may just as well result from still other sources and trajectories. And yet the synchronic states they yield are strikingly more uniform than expected by chance, and it is precisely for such situations that Haspelmath finds the costlier functional-adaptive motivations appropriate.

While the distinction between “recurrent patterns of change” and “mutational constraints” may be very difficult to maintain in practice, it highlights that alternative terms like “diachronic approach” or “diachronic explanation” are actually misleading: Both source- and result-oriented approaches in typology rely fundamentally on diachronic processes, as even result-oriented motivations must somehow be implemented in the developments that produce the synchronic pattern \citep{Haspelmath1999}. Haspelmath’s terminological proposal thus helps to clarify the essence of the contrast, which lies precisely in the theoretical status attributed to diachronic processes in the two approaches. 

At the same time, the opposition of “mutational” and “functional-adaptive” constraints makes one wonder whether the former are not also ultimately driven by functional motivations. We will return to this question in more detail in §2 again, but let us still ask at this point how supporters of source-oriented explanations \textit{motivate} the kinds of diachronic developments they discuss: They clearly argue against functional-adaptive, i.e. result-oriented, motivations in Haspelmath’s sense, but they neither claim that diachronic processes are entirely accidental\footnote{This even holds for Collins’ contribution, who claims that “some universals are historical \textit{accidents}” (p. \pageref{p:collins:historicalaccidents}): He uses the term “accidental” as an antonym of “functional-adaptive”, but not as a synonym of “random” or “chaotic”.}, nor that they are triggered by innate “representational constraints” (in Haspelmath’s terms)\footnote{Because of the latter, the debate in the present book – in contrast to earlier volumes on the topic (e.g. \citealt{Hawkins1988,Good2008}) – takes place entirely within the non-generative, i.e. usage-based, camp.}. It seems to us that source-oriented explanations are chiefly grounded in online processes of categorization and inferencing \citep{Bybee2010}, which can lead to the reanalysis of the form-function mappings in a given surface string (\citealt{Croft2000,DeSmet2009}). It is in this way that new grammatical markers (e.g. case or number morphemes) as well as new syntactic structures (e.g. Aux-V constructions) “naturally” emerge from pre-existing material, in all languages. To be sure, these diachronic processes work by applying domain-general cognitive mechanisms to communicative interactions, so they are \textit{ultimately} motivated in terms of these mechanisms. Crucially, however, the reanalysis itself is not adaptive in nature: It does not happen in order to produce a more efficient coding strategy for, say, number or case, or to disambiguate the core arguments of transitive clauses. This is one of Cristofaro’s major arguments for rejecting functional-adaptive motivations for case and number marking (and similar grammatical categories). If anything, then, the major mechanism of grammatical innovation in source-based accounts, i.e. reanalysis, is itself motivated by whatever perceptual, cognitive or communicative factors invite a reanalysis in the first place.\footnote{There are a number of interesting proposals as to the kinds of context that facilitate or even induce reanalysis (e.g. \citealt{DetgesWaltereit2002,HansenWaltereit2006,RosemeyerGrossman2017,SchwenterWaltereit2009,TraugottDasher2002}). To take but one recent example, \citet{Eckardt2009} argues that listeners typically reanalyze utterances in situations of “pragmatic overload”, e.g. utterances whose presuppositions are not easily accommodated.}

But a critical question is whether reanalysis is really the only way in which existing morphemes and constructions can give rise to grammatical innovations. Result-oriented approaches allow for the possibility that the agents of such innovations are not exclusively listeners (as in reanalysis), but also speakers. In particular, speakers may re-functionalize existing material in precisely those contexts where additional marking is felt to be beneficial for information processing. Some of the diachronic scenarios proposed in Michaelis’ paper appear to rely on this mechanism: She argues that when possessive person forms (e.g. \textit{your}) are employed to express a relatively unusual function, namely reference (\textit{yours}) instead of attribution, speakers summon additional marking to signal this deviation (see also \citealt{Croft1991,Croft2001} for a similar proposal). \citet{ZeevatJäger2002} refer to this functional-adaptive recruitment of marking as “annexation” or “semantic epenthesis”, and they use this mechanism to explain, for example, the rise of differential argument marking (e.g. the flagging of objects with statistically unexpected referential properties). Whether or not one finds these particular examples convincing, one could – in principle – imagine that some of the diachronic sources of plural marking that Cristofaro discusses are not due to reanalysis either, but go back further, namely to a speaker’s insertion of a lexical marker like ‘all’, ‘people’, etc. in contexts where plurality is relatively unexpected or in need of disambiguation (as in Present-Day English \textit{you} \textit{all,} \textit{you} \textit{guys,} etc.); it is only afterwards that such markers get reanalyzed and grammaticalized as plural morphemes, but their ultimate origin may have been a pattern of functional-adaptive “annexation”.\footnote{In \citegen{Croft2000} systematization of grammatical innovations, a mechanism very similar to annexation is actually described as a particular kind of reanalysis: In his so-called “cryptanalysis”, speakers feel that a conventionalized construction does not code an intended meaning component sufficiently and thus add appropriate material (e.g. double plurals like English \textit{feet-s} or Uzbek \textit{bi-z-lar} ‘we-\textsc{pl}{}-\textsc{pl’}, see also \citealt{Koch1995} for further examples from different grammatical domains). However, all of Croft’s examples differ from the above cases in that they already contain an overt grammatical marker that is analyzed as not being present (typically, it seems, as a result of chunking and entrenchment (\citealt{Bybee2015}: 102ff.)). The notion of annexation, by contrast, is intended to capture the \textit{first} kind of grammatical marking that arises (e.g. an accusative case marker on formerly bare object NPs). It is thus not a kind of contextual reanalysis of previously existing material, but the recruitment of a marker from another domain.} Therefore, although we will never be able to replay the innovation of highly grammaticalized markers, we should not exclude a priori the possibility that it is driven by processes other than reanalysis. 

An immediately related issue is that source-based typologies also tend to be too narrow on another plane: When Cristofaro pleads to “take diachronic evidence seriously” (p. \pageref{p:cristofaro:evidenceseriously}), one wonders why her arguments against particular functional motivations revolve entirely around the innovation stage of grammatical change, to the exclusion of further developments. The contributions by Schmidtke-Bode and by Seržant highlight the importance of diffusion processes, i.e. the gradual extension of innovations to new environments, and particularly also stages at which the use of a grammatical marker is (still) variable. There is ample evidence from corpus data, grammatical descriptions, psycholinguistic experimentation and, as Levshina’s paper shows, from artificial language learning, that a significant part of such variability is driven by functional-adaptive motivations. Therefore, we believe that a more appropriate way of taking diachronic evidence seriously would be to return to \citegen{Bybee1988} original formulation: Bybee argues that, for functional-adaptive explanations to be valid, “it must be shown that the factor appealed to as explanation actually contributes to the creation of the particular grammatical convention” \citep[357]{Bybee1988}. As the creation of a grammatical convention goes well beyond the processes and motivations by which a pattern first arose, the absence of evidence for functional-adaptive motivations at the innovation stage does not provide evidence for the absence of such motivations in the development of the grammatical pattern in question.

This leads us (back) to the nature of the evidence that is brought to bear on the present discussion. Haspelmath adopts the strong position that “diachronic evidence is not strictly speaking necessary” (p. \pageref{p:haspelmath:strictlyspeakingnecessary}) to explain a typological regularity in functional-adaptive terms. This radical position appears to stem, at least in part, from the observation that where we do have pieces of diachronic stories, it often seems to be the case that “all diachronic roads lead to the same synchronic Rome” \citep[38]{Kiparsky2008}. In other words, one and the same typological state can arise in manifold ways, which Haspelmath (just like Kiparsky) takes as evidence for convergent evolution towards a common attractor state. This is perhaps one of the most interesting aspects of the present debate, as exactly the same type of evidence (i.e. the available or reconstructed historical data) is interpreted in opposite ways. Michaelis’ contribution endorses the Haspelmath–Kiparsky stance: the coding asymmetry between attributive and referential possessive forms is sometimes due to phonetic reduction processes in the more predictable (i.e. the attributive) function, and often due to the annexation and grammaticalization of more coding material in the less predictable (i.e. the referential) function, and again from a variety of different sources. Cristofaro, by contrast, argues (for number marking) that the phonetic erosion of overt singulars may have various language-internal motivations, and that the sheer variety of different sources for the grammaticalization of new plural markers does simply not point towards a single, unifying force. There is no obvious way to settle this issue, given the above-mentioned quantity and depth of resolution of actual diachronic data. This is exactly why proponents of functional-adaptive motivations have long sought to triangulate typological data with behavioural evidence from other sources.

Within the confines of the present volume, we have not been able to represent most of these other data sources, but the contributions by Seržant and by Levshina do highlight the potential of analyzing performance data from historical transition phases and from artificial language learning, respectively. The latter is a relatively novel experimental paradigm that, despite certain drawbacks (e.g. potential L1 influence), provides a useful addition to classic psycholinguistic, neurolinguistic and simulative experimentation on typologically relevant phenomena (see, e.g. \citealt{KurumadaJaeger2015,BickelEtAl2015,Lestrade2018} for these different types of data on typological preferences in case marking). All of these performance data point to the existence of functional-adaptive forces in grammar and hence cannot be neglected in the study of typological patterns. In fact, the recent movement in usage-based linguistics to view language as an instance of a “complex \textit{adaptive} system” (e.g. \citealt{Gell-Mann1992,BecknerEtAl2009}) suggests that grammatical structure is shaped over time to adapt to interlocutors’ (partially conflicting) needs. 

At the same time, another important property of such complex adaptive systems is that their developmental trajectories crucially depend on the system’s initial conditions – i.e. precisely on the nature of each “source construction”. This ties in nicely with Cristofaro’s (p. \pageref{p:cristofaro:commonalitiesexceptions}) argument that a source-based approach to universals is not only able to capture the cross-linguistic commonalities (because there are, after all, strong preferences in the kinds of grammaticalization processes that happen across languages) but also the exceptions: The latter, she argues, also fall out directly from the initial conditions, in that the languages with exceptional patterns may have different source constructions, or even no sources of the relevant type.\footnote{This argument is also supported by Diessel’s contribution: He shows that instances of postposed adverbial clauses with final subordinators (‘his going-to-the-movies because’) are unexpected from a processing perspective, but receive a natural explanation in diachronic terms if one realizes that these structures exist in OV languages which place the source construction, i.e. oblique PPs, in postverbal rather than preverbal position.}  

While this is an attractive (again: “low-cost”) proposal, we feel that it needs to be made more rigorous. At present, source-oriented accounts are often selective in their interpretation of the data. For example, when Cristofaro (p. \pageref{p:cristofaro:ergatives}) claims that ergatives do not apply to first- and second-person pronouns because their instrumental source tended not to do so either (for obvious semantic reasons), one wonders why the same kind of restriction does not carry over to similar cases. For instance, \citet[36]{Kiparsky2008} mentions, among quite a few other examples, that when ablatives develop from a source with separative meaning (‘away from X’), these sources are often limited to animates and physical objects, “and yet we don't find ablatives with zero allomorphs on abstract nouns”. In other words, purely source-based accounts are sometimes too general, as they predict all kinds of restrictions that get levelled as diachrony unfolds. Conversely, they can also be too limited because, as noted by \citet{Kiparsky2008} as well, some synchronic patterns of differential marking are rather difficult to derive from their sources (e.g. animacy restrictions on the Genitive in Yukaghir). While Kiparsky’s critique was directed chiefly against \citet{Garrett1990}, it seems to us that the same argument applies to more recent incarnations of source-oriented explanations.

This observation rounds off our survey of the arguments laid out in the volume, and we now proceed to some implications from and possible future directions for the debate as a whole.

\section{Lessons, challenges and future directions}

One important general lesson from Haspelmath’s lead article is that the very notion of “diachronic explanation” in typology is too vague, as both source- and result-oriented explanations crucially involve diachronic processes, but in different ways (see §1 above). Furthermore, it is necessary to specify the requirements, as Haspelmath does, on when a so-called source-oriented account of universals is considered a genuine explanation, which is precisely what a terminological proposal like “mutational explanation” is meant to capture. But it is less clear to us whether such a mutational explanation is best described as a “constraint” on language, and whether it is as such felicitously juxtaposed with “functional-adaptive”, “acquisitional” and “representational” constraints (Haspelmath, p. \pageref{p:haspelmathLrepresentationalconstraints}). The primary reason for this uncertainty is that “mutational constraints”, unlike the others proposed by Haspelmath, do not have a clear locus, as it were. The changes they are intended to capture are themselves rooted in forces operating on language users (and thus ultimately on language systems) and these could, in principle, be functional-adaptive constraints, constraints on learning or constraints on change from innate linguistic representations, and possibly others. In other words, “mutational constraints” are always due to something else, something that really constrains the mutations (as Haspelmath notes himself (p. \pageref{fn:haspelmath:mutationalconstraints}, fn. \ref{fn:haspelmath:mutationalconstraints})), and so they do not, strictly speaking, form a paradigmatic opposition with these other constraints.

To give just one example, Haspelmath argues that the universal generalization that all languages with nasal vowels also have nasal consonants can be accounted for directly by the restricted ways in which nasal vowels come about, i.e. most typically by regressive assimilation to a following nasal consonant. But this mutational constraint is motivated, at least in part, by processes that one may well describe as “functional”, viz. the anticipation and consequent retiming of articulatory gestures that come with repeated exposure and practice of the VC sequences in question (\citealt{Bybee2015}: 38; but cf. \citealt{Ohala1989,Ohala2003} for alternative explanations). Is this “functional” in the sense of “functional-adaptive” (because it \textit{results} \textit{in} easier or more economical articulation for the speaker) or in the sense of being a natural consequence of frequency-based memory representations and our predictions based on those frequencies? In the latter case, could this possibly count as a “representational constraint”? According to Haspelmath, it cannot, because the representational constraints he envisages are innate linguistic representations (= “costly” stipulations of structure that cannot be explained in more direct terms). But then it is unclear how to classify the frequency effects from exemplar representations that are not straightforwardly adaptive in nature, such as some of the “conserving effects of token frequency” discussed in many places by Bybee and others (e.g. \citealt{BybeeThompson1997,Pierrehumbert2001,Bybee2001}; see also \citealt{Cristofaro2015} for discussion): Well-entrenched representations are more resistant to change, but that does not necessarily mean that they make speaker-hearer interactions (or a linguistic system) more efficient or otherwise better adapted.\footnote{Incidentally, Diessel’s contribution also distinguishes between “functional” and “cognitive” motivations for the development of preposed adverbial clauses (p. \pageref{p:diessel:preposedadverbialclauses}). The former relate, for example, to information structure and iconicity, and are adaptive in Haspelmath’s sense. The latter refer to the cognitive processes involved in the grammaticalization of adverbial clauses, notably “automatization, semantic bleaching and formal reduction” (p. \pageref{p:xxx:automatization}). Apparently, then, these specific effects of cognitive representation are to be kept distinct from “functional” factors, which shows that they do not fit easily into Haspelmath’s typology of constraints.}  Similar remarks apply to the pragmatic processes that constrain reanalysis (see fn. \ref{fn:epilog:8} above): These are quite systematic and thus principled constraints on the development of languages, yet they are not adaptive according to Haspelmath’s definition and, therefore, defy classification according to his schema.

A related difficulty pertains to the separation of representational and acquisitional constraints (see also Levshina’s paper). In generative approaches, innate representations are invoked precisely in order to solve learnability problems, making it hard to draw the line between acquisition and representation. In non-generative approaches, by contrast, a constraint on acquisition only makes sense if it can be disentangled from functional-adaptive constraints (cf. “What is functional is learnt best”). And crucially, in both approaches it would have to be shown that processes of language learning are causally involved in the diachronic development of languages. While much scepticism has been voiced that (monolingual) L1 acquisition should be causally related to language change (see e.g., \citealt{Croft2000,HeineKuteva2007,Diessel2011} for recent surveys), it is very likely that certain forms of bilingualism and L2 acquisition play such a causal role, namely in situations of language contact (\citealt{Matras2009,MeiselEtAl2013,Gast2017} and many others). But then again, the difficulty remains of separating the acquisition processes from either representational or functional-adaptive forces involved in them.\footnote{More generally, the issue of language contact has received rather little attention in this volume (apart from Michaelis’ contribution on contact languages, of course). Needless to say, we do not wish to marginalize the role of contact for diachronic development. But for one thing, the entire discussion revolves around the notion of universals, which are usually seen as “distilled” properties of linguistic structure after contact-induced similarities are controlled for \citep{Bickel2011}. Secondly, as argued above, what happens in contact situations deserves its own detailed investigation in order to clearly disentangle different types of forces on diachronic development in these contexts. This may reveal similar pressures on development as in non-contact languages (as argued by Michaelis) or else point to the overriding importance of other, more contact-specific, factors (e.g. patterns of L2 learning, constraints on borrowing, etc.). See also \citet{Matras2009} for a book-length survey of these issues, and \citet{Hickey2017} for a state-of-the-art collection on areal linguistics.}

It is beyond the scope of this short epilogue to elaborate on these important issues. The critical point is simply that Haspelmath’s constraint typology must be interpreted carefully for what it is, namely a typology of different types of explanation: If we neglect the more elusive acquisitional constraints for now, the three remaining “mutational”, “functional-adaptive” and “(UG-)representational” approaches indeed constitute three very different practices of explaining how universals in language develop. And as such, they can plausibly be ranked on a cost scale which characterizes the number of explanatory principles beyond those that are necessary to explain the origin of each individual construction in one’s sample (mutational > functional-adaptive > UG-representational). But this does not exhaust what we may wish to call constraints on language, i.e. the sum of all pressures or forces that “cause languages to change in preferred or ‘natural’ ways” (\citealt{BickelEtAl2015}: 29). The different types of explanation rather highlight that there either is or is not more to the motivation of language universals than the persisting properties of individual source constructions.\footnote{Ultimately, such a typology of constraints on language would have to accommodate, for example, environmental factors (humidity, altitude), socio-cultural factors (population size, sociocultural practices, social goals in communication), communicative/pragmatic factors (biases in inference making and the resulting utterance interpretation) and cognitive factors, with the latter to be worked out more specifically in terms of whether or not they are domain-general abilities or domain-specific biases and to what extent they are innate or learned. Some recent systematizations include \citet{ChristiansenChater2008}, \citet{EvansLevinson2009} and \citet{Bybee2010}, but none of them addresses all of the above dimensions (or claims to be exhaustive).} 

Our own view is that persistence effects from source constructions are one of many forces which constrain the development of linguistic structure and thus have a role to play in the explanation of universals pertaining to these structures. But as laid out in §1 above, they are rarely ever the whole story. Seržant’s contribution to the present volume is particularly insightful in this regard, as he shows that the respective sources of individual differential object markers exert a strong influence on the current use of these markers, but that functional-adaptive considerations of efficient information processing (particularly ambiguity avoidance) interact with the source meaning at particular historical stages, and can even pave the way for the further development of the marker in question. So, just as we argued above, each synchronic state of a complex adaptive system depends to some extent on its initial conditions; but it is adaptive nevertheless. As \citet[263]{Shibatani2006} puts it, a language should be seen “as a historically-evolving functional organism sustaining constant pressure for adaptation”. 

Therefore, while the present volume sought to encourage a lively debate between, and hence often a rigid juxtaposition of, source- and result-oriented explanations, it seems likely that most typological phenomena will need a nuanced mixture of both (see also Dryer’s and Diessel’s contributions to this volume). In fact, this echoes an assessment given by Nichols (2008: 287–288):

\begin{quote}
Rather than synchronic patterns always being the goal and driving force of language change, various synchronic patterns are the predictable consequences of diachronic processes which have their own logic independent of the synchrony they produce. Thus, to a greater extent than [one might presume], synchronic structural patterns are epiphenomenal. But they are not entirely so. Economies of various kinds appear to be targets of change […], and there appear to be […] structural patterns that may be goals of change but are not its accidental results.
\end{quote}

The methodological challenge ahead is thus to calibrate more precisely, for each grammatical domain and typological generalization at a time, how much room for functional-adaptive motivations is left once one controls for persistence effects in the data as much as possible. As Collins (p. \pageref{p:collins:dependency}) reminds us, constraints inherited from the source add yet another kind of dependency (on top of areal and genealogical relations) to typological samples. It then becomes an empirical question whether the sources are so clearly circumscribed that they, indeed, suggest a mutational explanation and give us the synchronic distributions for free, or whether it is necessary to resort to costlier explanations along functional-adaptive lines that go beyond the individual sources.

Another avenue for conceptual work on universals and diachrony would be to expand and flesh out a framework developed by \citet{Greenberg1978,Nichols1992,Nichols2003} and \citet{Bickel2013}. This framework lays the conceptual foundations for modelling probabilities of cross-linguistic unity and diversity in diachronic terms. For example, according to \citet[76]{Greenberg1978}, a particular linguistic phenomenon should be universal or near-universal “if it can arise very frequently and is highly stable once it occurs. [… ] If a particular property rarely arises but is highly stable when it occurs, it should be fairly frequent on a global basis but be largely confined to a few linguistic stocks.” Nichols (2003: 287–288) further develops such predictions by bringing contact-induced phenomena (borrowing and substrate influence) and functional-adaptive factors (“harmony”, “unmarkedness”) into the equation. Elaborating these lines of thinking, one may look at some of the themes of the present volume in the following way (see \citealt{Grossman2016} and \citealt{GrossmanEtAl2018} for more details):

\ea
Types of diachronic influence on language universals\\
  \ea \textsc{source}: frequency of the source construction \citepv{Cristofaro2019tv}
  \ex \textsc{type}: frequency of type of change (e.g. assimilatory changes are more common than dissimilatory ones). This has rarely been studied on the basis of large samples and for a wider range of phenomena (largely due to the epistemological problems discussed in §1 above), thus constituting a desideratum in typological research.
  \ex \textsc{path}: number of pathways that lead to a particular item type (e.g. \citealt{BybeeEtAl1994} on tense-aspect-mood constructions)
  \ex \textsc{stage}: number of stages necessary to yield a certain outcome (e.g. \citealt{Harris2008})
  \ex \textsc{stability}: inherent stability of item type (\citealt{Greenberg1978}, \citealt{Nichols2003}) 
  \ex \textsc{diffusability:} likelihood to diffuse through contact (borrowing, calquing, contact-induced grammaticalization)
  \z
\z

Note that (a), (b), (e) and (f) may themselves be causally related to functional-adaptive forces. For example, a given phenomenon may be faithfully inherited and hence be diachronically stable precisely because it is adaptive in Haspelmath’s sense; and it may easily diffuse in language contact for the same reason (see also \citealt{Bickel2013,Bickel2017} for the same observations). 
Just as in \citet{Greenberg1978}, then, the basic idea is that the more these factors converge, the stronger the cross-linguistic preponderance of the structure in question. In other words, if a property develops from cross-linguistically frequent sources, as a result of common types of change that involve few stages, if there are multiple pathways that lead to it, it is stable once present, and it is likely to diffuse through borrowing, this property is predicted to be (nearly) universal. Conversely, a property that involves rare source constructions, rare changes, and so on, is predicted to be cross-linguistically rare or limited areally and/or phylogenetically. Of course, these factors might have varying strengths, and it is a goal of typological research to determine their relative ranking for each case in question. For example, it may be that a property develops often, from multiple and common sources, but if it is inherently unstable – say, due to a strong functional-adaptive pressure to eliminate it – then it is predicted to be sporadically attested areally and genealogically. If it is diffusable, then it has a good chance to take root in particular areas. In phonology, for example, this seems to be the case for aspirated fricatives \citep{Jacques2011} and for affricate-rich systems (\citealt{NikolaevGrossman2018}), the latter of which are diachronically unstable unless supported areally. As far as we are aware, Bickel’s (\citeyear{Bickel2011,Bickel2013}) Family Bias Method has offered the first principled way of incorporating some of these considerations into actual typological methodology. It is to be hoped that such methods, alongside more classic sampling methods with built-in controls for source-related dependencies (as suggested above), will become de rigeur in future typological research.

Above all, we hope that the present volume has offered an insight into current ways of thinking about the role of diachronic processes in explaining universal generalizations, and that it has contributed to specifying the arguments, strengths and weaknesses of different positions in that debate.

 

\end{document}