\documentclass[output=paper]{langsci/langscibook} 
\author{Karsten Schmidtke-Bode\affiliation{Leipzig University}}
\title{Introduction}
\abstract{}
\begin{document}
\maketitle 

\title{\textsuperscript{}}





The present volume addresses a foundational issue in linguistic typology and language science more generally. It concerns the kinds of explanation that typologists provide for the cross-linguistic generalizations they uncover, i.e. for so-called universals of language. The universals at issue here are usually probabilistic statements about the distribution of specific structures, such as the classic Greenbergian generalizations about word order and morphological markedness patterns. Some examples are given in (1)–(4) below:

\ea 
{With overwhelmingly greater than chance frequency, languages with normal SOV order are postpositional. \citep[79]{Greenberg1963}}\\
\z
\ea\label{ex:key:}
{A language never has more gender categories in nonsingular numbers than in the singular. \citep[95]{Greenberg1963}}\\
\z
\ea\label{ex:key:}
{If a language uses an overt inflection for the singular, then it also uses an overt inflection for the plural. (\citealt{Croft2003}: 89, based on \citealt{Greenberg1966}: 28)}\\
\z 
\ea\label{ex:key:}
{In their historical evolution, languages are more likely to maintain and develop non-ergative case-marking systems (treating S and A alike) than ergative case-marking systems (splitting S and A). (\citealt{BickelEtAl2015}: 5)}\\
\z

As can be seen from these examples, cross-linguistic generalizations of this kind may be formulated in terms of preferred types in synchronic samples or in terms of higher transition probabilities for these types in diachronic change (see also \citealt{Greenberg1978,Maslova2000,Cysouw2011,Bickel2013} for discussion of the latter approach). But this is, strictly speaking, independent of the question we are primarily concerned with here, namely how to best account for such generalizations once they have been established.

The most widespread typological approach to explanation is grounded in functional properties of the preferred structural types: For example, typical correlations in the ordering of different types of phrases (e.g. object–verb and NP–postposition) have been argued to allow efficient online processing (e.g. \citealt{Hawkins1994}; 2004). Markedness patterns in morphology (e.g. the distribution of zero expression in case, number or person systems) have been attributed to economy, i.e. the desire to leave the most frequent and hence most predictable constellations unexpressed, or rather to a competition between economy and the motivation to code all semantic distinctions explicitly (e.g. \citealt{Haiman1983,Comrie1989,Aissen2003,Croft2003,Haspelmath2008}; among many others). The general idea behind this approach is thus that speech communities around the world are subject to the same kinds of cognitive and communicative pressures, and that the languages they speak tend to develop structures that respond to these pressures accordingly, or, as \citet[118]{Bickel2014} puts it, “in such a way as to fit into the natural and social eco-system of speakers: that they are easy to process, that they map easily to patterns in nonlinguistic cognition, and that they match the social and communicative needs of speakers.” 

There is a clear parallel to evolutionary biology here, in that languages are said to \textit{converge} on similar structural solutions under the same functional pressures, just like unrelated species tend to develop similar morphological shapes in order to be optimally adapted to the specific environment they co-inhabit (\citealt{Deacon1997,Caldwell2008,EvansLevinson2009,Givón2010}). When applied to language, this line of explanation at least implicitly invokes what is known as “attractor states”, i.e. patterns of structural organization that languages are drawn into in their course of development.\footnote{The term attractor state (or basin of attraction) is adopted from the theory of complex dynamic systems (e.g.  \citealt{Cooper1999,HoweLewis2005,Holland2006}), which has become increasingly popular as a way of viewing linguistic systems as well (see \citealt{BecknerEtAl2009} and \citealt{Port2009} for general overviews, and \citealt{Haig2018} or \citealt{Nichols2018} for very recent applications to typological data).} For this reason, one could also speak of a \textbf{result-oriented} approach to explanation. 

There is, however, another way of looking at the same patterns, one that redirects attention from the functional properties to the diachronic origins of the linguistic structures in question. On this view, many universal tendencies of order and coding are seen as by-products, as it were, of recurrent processes of morphosyntactic change, notably grammaticalization, but without being adaptive in the above sense: There is no principled convergence on similar structural traits because these traits might be beneficial from the perspective of processing, iconicity or economical communicative behaviour. Instead, the current synchronic distributions are argued to be long-term reflections of individual diachronic trajectories, in particular the diachronic sources from which the structures in question originate. \citet{Givón1984} and \citet{Aristar1991}, for example, suggested that certain word-order correlations may simply be a consequence of a given ordering pair (e.g. Gen–N \& Rel–N, or V–O \& Aux–V) being directly related diachronically: Auxiliaries normally grammaticalize from main verbs that take other verbs as complements, and since these complements follow the verb in VO languages, they also follow the auxiliary in the resulting Aux–V construction; the mirror-image pattern holds for OV languages (see also \citealt{Lehmann1986}: 12–13). If this line of reasoning extends to most other word-order pairs, there is no need to motivate the synchronic correlations in functional-adaptive terms, e.g. by saying that the correlations arise \textit{in} \textit{order} \textit{to} facilitate efficient sentence processing. 

In the domain of morphology, \citet{Garrett1990} argued that patterns in case marking, specifically of differential ergative marking, are exhaustively explained by the properties of the source of the ergative marker: When ergative case arises from the reanalysis of instrumental case, the original characteristics of the latter, such as a restriction to inanimate referents, are directly bequeathed to the former. The result is a pattern in which animate A-arguments are left unmarked, but since this is a direct “persistence effect” \citep{Hopper1991} of the history of the ergative marker, there is again no need for an additional functional-adaptive explanation in terms of other principles, such as a drive for economical coding patterns. Rather than being result-oriented, then, this way of explaining universals can be characterized as \textbf{source-oriented}.

Such source-oriented explanations thus move away from attractor states of grammatical organization and often emphasize the importance of “attractor trajectories” instead (\citealt{BybeeBeckner2015}: 185): In some domains of grammar, the patterns of reanalysis and ensuing grammaticalization are so strikingly similar across the world’s languages that it is not surprising that they yield similar outcomes, such as strong correlations between V–O \& Aux–V or V–O \& P–NP ordering. In other cases, it is argued that many individual, and partly very different, diachronies are capable of producing a uniform result, but without any consistent functional force driving these trajectories. \citet{Cristofaro2017}, for instance, claims that this is the case for plural markers: An initial system without number marking can develop an overt plural morpheme from many different sources – usually by contextual reanalysis – and thus ultimately come to contrast a zero singular with an overt plural, but these developments are neither triggered nor further orchestrated by a need for economical coding: They do not happen to keep the (generally more frequent) singular unmarked and the (generally less frequent) plural overtly signalled. 

In other words, whether the individual diachronic trajectories are highly similar or rather diverse, the premise of the source-oriented approach is that they can scale up to produce a predominant structural pattern in synchronic samples. Hence they obviate the need for highly general functional principles tying these patterns together.

While the source-oriented approach was still a more marginal position in previous volumes on explaining language universals (e.g. \citealt{Hawkins1988a,Good2008}), it has gained considerable ground over the last decade, notably in a series of articles by Cristofaro (e.g. \citealt{Cristofaro2012}; 2014; 2017) but also in other publications (e.g. \citealt{Creissels2008,GildeaZúñiga2016}). Moreover, while the basic thrust of the two explanatory approaches is straightforward, clarification is needed on a number of – equally fundamental – details. After all, both approaches are functionalist in nature, as they rely on domain-general mechanisms (\citealt{Bybee2010}) to explain the emergence of language structure and linguistic universals; and in both approaches, these mechanisms constrain how languages “evolve into the variation states to which implicational and distributional universals refer” \citep[18]{Hawkins1988b}. But as \citet[51]{Plank2007} notes, “what is supposed to be the essence and force of diachronic constraints would merit livelier discussion.” It is the goal of the present book to offer precisely a discussion of this kind.

The volume begins with a programmatic paper by \textbf{Martin Haspelmath} on what it means to explain a universal in diachronic terms. He aims to clarify how diachrony is involved in result-oriented and source-oriented accounts, respectively, and thus lays out a general conceptual framework for the explanation of universals. At the same time, Haspelmath opens the floor for debating the strengths and weaknesses of the two explanatory accounts at issue here. His own position is that, in many cases, current source-oriented explanations are ill-equipped to truly explain the phenomena they intend to account for, and hence cannot replace result-oriented motivations. Haspelmath’s arguments for this position, as well as his terminological proposals, provide a frame of reference to which all other contributions respond in one way or another.

The lead article is followed by two endorsements of source-oriented explanations, articulated by \textbf{Sonia Cristofaro} and \textbf{Jeremy Collins}, respectively. They both describe the approach in widely accessible terms, allowing also readers outside of linguistic typology to appreciate the general argument as well as the specific examples discussed. The phenomena themselves involve domains that are particularly well-known for being explained in functional-adaptive terms, namely differential argument marking, number marking and word-order correlations, and these are all argued to be best captured by persistence effects from their respective diachronic origins.  

We then proceed to papers that allow for progressively more room for functional-adaptive motivations and, importantly, for methodological discussions on how to obtain evidence for such pressures. Accordingly, all of these papers adduce novel empirical data and discuss them in light of the present debate.

\textbf{Matthew Dryer}’s paper is an immediate follow-up on Collins’ discussion of word-order correlations. On the one hand, Dryer argues that the various correlates of adposition–noun ordering (e.g. OV and NP–P, and Gen–N and NP–P) are, indeed, best accounted for in source-oriented terms. In particular, only this approach proves capable of explaining the occurrence (and the individual semantic types) of both prepositions and postpositions in SVO languages. On the other hand, however, Dryer contends that there are some significant correlations for which a source-based account either fails to offer an explanation or else makes the opposite prediction of the patterns we find synchronically. Dryer concludes, therefore, that neither a purely source-based nor a purely result-based explanation is sufficient to deal with word-order correlations.      

In a similar fashion as Dryer’s paper, \textbf{Holger Diessel}’s article demonstrates that different aspects of the same grammatical domain – in this case adverbial clause combinations – are amenable to different types of explanation. Diessel focuses specifically on the structure and development of preposed adverbial clauses and argues that some of their typological characteristics, notably the properties of their subordinating morphemes, receive a satisfactory explanation in terms of the respective source construction(s), thereby supplanting earlier processing-based explanations. On the other hand, he proposes that the position of adverbial constructions (in general) is clearly subject to a number of functional-adaptive pressures, and that these may already have affected the diachronic sources from which the current preposed adverbial clauses have grammaticalized.

\textbf{Karsten Schmidtke-Bode} offers a review of Hawkins’ (2004, 2014) research programme of “processing typology”, examining the plausibility of Hawkins’ functional-adaptive ideas in diachronic perspective. On a theoretical level, it is argued that a predilection for efficient information processing is operative mostly at the diffusion stage of language change, regardless of the source from which the respective constructions originate. On a methodological level, the paper proposes that the cross-linguistic predictions of Hawkins’ programme can be tested more rigorously than hitherto by combining static and dynamic statistical models of large typological data sets; this is demonstrated in a case study on the distribution of article morphemes in VO- and OV-languages, respectively.

An important methodological point is also made by \textbf{Ilja A. Seržant}, who claims that certain functional-adaptive pressures may not actually surface in standard typological analysis because they are weak forces, clearly at work but also easily overridden by other, language-specific factors. Because of their weak nature, they may not be directly visible any-more in a synchronic type, but they can be detected in qualitative data from transition phases. Based on diachronic data from Russian, Seržant shows how the development of differential object marking was crucially influenced by considerations of ambiguity avoidance (and hence a classic functional-adaptive motivation), over and above the constraints inherited from the source construction. In the absence of such longitudinal data, transition phases can be identified on the basis of syn-chronic variability, and Seržant shows that a wide variety of languages currently exhibit variation in differential object marking that mirrors the diachronic findings from Russian, and that is not predictable from the source meaning of the marker in question.

\textbf{Susanne Maria Michaelis} adds another source of data to the debate at hand. She argues that creole languages provide a unique window onto the relationship between synchronic grammatical patterns and their diachronic trajectories, as the latter are often relatively recent and also accelerated when compared to normal rates of grammatical change. The developments are, consequently, more directly accessible and less opaque than in many other cases. By inspecting creole data on possessive forms in attributive and referential function (e.g. \textit{your} versus \textit{yours}), Michaelis finds evidence for the development of the same kinds of coding asymmetries that this domain offers in non-contact languages around the world. She proposes that the data are indicative of result-oriented forces that drive diverse diachronic pathways towards the same synchronic outcome. This stance contrasts most explicitly with Cristofaro’s, who interprets such situations in exactly the opposite way (i.e. as providing evidence \textit{against} a unifying functional explanation).

\textbf{Natalia Levshina}, finally, adopts an entirely different methodological approach to illuminate the present discussion: In her paper, she showcases the paradigm of artificial language learning, which can be employed to inspect whether users of such newly acquired languages develop performance biases that are in keeping with hypothesized functional principles, such as an increasingly efficient distribution of morphological marking. Her case study clearly demonstrates such biases and discusses where they may ultimately come from, i.e. how they fit into the new conceptual framework of constraints offered by Haspelmath’s position paper.

The volume is rounded off by a brief \textbf{epilogue} in which \textbf{Karsten Schmidtke-Bode} and \textbf{Eitan Grossman} summarize and further contextualize the arguments put forward by the contributors. 

Overall, the purpose of the present book is to provide a state-of-the-art overview of the general tension between source- and result-oriented explanations in linguistic typology, and specifically of the kinds of arguments and data sources that are (or can be) brought to bear on the issue. It should be made clear from the outset that the two types of explanation are framed as antagonistic here even though in most cases, an element of both will be needed in order to fully account for a given grammatical domain. As we emphasize in the epilogue, the diachronic source of a grammatical construction certainly constrains its further development, but the major issue at stake here is the extent to which result-oriented, functional-adaptive motivations enter these developments as well. By the end of the day, universals of language structure will thus differ in the \textit{degree} to which they are shaped by such adaptive pressures.

\section*{Acknowledgements}

The present volume originated in the context of the project \textit{Form-frequency} \textit{correspondences} \textit{in} \textit{grammar} at Leipzig University. The support of the European Research Council (ERC Advanced Grant 670985, Grammatical Universals) is gratefully acknowledged. An oral precursor to this volume was a workshop on the topic at the 49\textsuperscript{th} Annual Conference of the Societas Linguistica Europaea in Naples in 2016, co-organized by the editors of this book. We would like to thank the participants and the audience of that workshop for insightful contributions and discussion. We would also like to thank Eitan Grossman and Mark Dingemanse for extensive feedback on all papers in the present volume. Finally, we are grateful to Sebastian Nordhoff and his team at Language Science Press as well as the participants of Language Science Press’s community proofreading.

 
\end{document}